---
title: 'Word Learning: Manuscript Analsysis'
author: "Kimberly A. Brink"
date: "5/30/2017"
output: html_document
---

"Word Learning" is a study that assesses whether children will selectively trust a robot that provides accurate information compared to a robot that provides inaccurate information. Children watch two robots name a series of familiar objects, where one robot always names the object correctly and the other robot always incorrectly names the robot. The two robots are distingushed by their colors. 


```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.path='Figures/', dev=c('svg','postscript'), fig.width = 8, fig.height = 8, echo=FALSE, warning=FALSE, message=FALSE)
```

```{r standard_error}
std.error <- function(x) sd(x,na.rm=TRUE)/sqrt(length(x))
```

```{r libraries}
library(lubridate)
library(pander)
library(MASS)
library(QuantPsyc)
library(ggplot2)
library(reshape2)
library(wesanderson)
options("scipen"=100, "digits"= 4)
```

```{r settings}
color = rgb(249/255,175/255,61/255)

wesanderson = "Moonrise3"

```

#Word Learning 1: Experimental Condition
```{r WL1_import}
source("~/Dropbox/Research/Michigan/Dissertation - Robots/Word Learning/Private/WL1_data.R")
```

```{r WL1_formatting}
#Clean the data set

#Subset the data set by condition (i.e., by the order in which the robots are presented and by which robot is accurate)
WL1.A <- subset(qualtrics.WL1, Condition==1 & AccurateRobot=='Purple')
WL1.B <- subset(qualtrics.WL1, Condition==2 & AccurateRobot=='Purple')
WL1.C <- subset(qualtrics.WL1, Condition==1 & AccurateRobot=='Orange')
WL1.D <- subset(qualtrics.WL1, Condition==2 & AccurateRobot=='Orange')

#Each condition of the survey has different question names for the same questions. 
#Remove all unused variable names from each condition

WL1.A <- WL1.A[, c("ResponseID","StartDate","Finished","Condition","AccurateRobot","Subject","Sex","DOB","DOT","Fam1","Fam1_TEXT","Fam2","Fam2_TEXT","Fam3","Fam3_TEXT","Fam4","Fam4_TEXT","EJ1","Ask1A","Ask1A_TEXT","Ask1B","Ask1C","Ask2A","Ask2A_TEXT","Ask2B","Ask2C","Ask3A","Ask3A_TEXT","Ask3B","Ask3C","Ask4A","Ask4A_TEXT","Ask4B","Ask4C","EJ2","WHYCHOOSE","WHY","CANDY","CHOOSE","THINK","MORAL","PAIN","FEELINGS","SCARED","HUNGRY","P.SEX","O.SEX","OLDER","Audio_file","Comments")] 

WL1.B <- WL1.B[, c("ResponseID","StartDate","Finished","Condition","AccurateRobot","Subject","Sex","DOB","DOT","Fam1.2","Fam1_TEXT.2","Fam2.2","Fam2_TEXT.2","Fam3.2","Fam3_TEXT.2","Fam4.2","Fam4_TEXT.2","EJ1.2","Ask1A.1","Ask1A_TEXT.1","Ask1B.1","Ask1C.1","Ask2A.1","Ask2A_TEXT.1","Ask2B.1","Ask2C.1","Ask3A.1","Ask3A_TEXT.1","Ask3B.1","Ask3C.1","Ask4A.1","Ask4A_TEXT.1","Ask4B.1","Ask4C.1","EJ2.1","WHYCHOOSE","WHY","CANDY","CHOOSE","THINK","MORAL","PAIN","FEELINGS","SCARED","HUNGRY","P.SEX","O.SEX","OLDER","Audio_file","Comments")]

WL1.C <- WL1.C[, c("ResponseID","StartDate","Finished","Condition","AccurateRobot","Subject","Sex","DOB","DOT","Fam1.1","Fam1_TEXT.1","Fam2.1","Fam2_TEXT.1","Fam3.1","Fam3_TEXT.1","Fam4.1","Fam4_TEXT.1","EJ1.1","Ask1A","Ask1A_TEXT","Ask1B","Ask1C","Ask2A","Ask2A_TEXT","Ask2B","Ask2C","Ask3A","Ask3A_TEXT","Ask3B","Ask3C","Ask4A","Ask4A_TEXT","Ask4B","Ask4C","EJ2","WHYCHOOSE","WHY","CANDY","CHOOSE","THINK","MORAL","PAIN","FEELINGS","SCARED","HUNGRY","P.SEX","O.SEX","OLDER","Audio_file","Comments")] 

WL1.D <- WL1.D[, c("ResponseID","StartDate","Finished","Condition","AccurateRobot","Subject","Sex","DOB","DOT","Fam1.3","Fam1_TEXT.3","Fam2.3","Fam2_TEXT.3","Fam3.3","Fam3_TEXT.3","Fam4.3","Fam4_TEXT.3","EJ1.3","Ask1A.1","Ask1A_TEXT.1","Ask1B.1","Ask1C.1","Ask2A.1","Ask2A_TEXT.1","Ask2B.1","Ask2C.1","Ask3A.1","Ask3A_TEXT.1","Ask3B.1","Ask3C.1","Ask4A.1","Ask4A_TEXT.1","Ask4B.1","Ask4C.1","EJ2.1","WHYCHOOSE","WHY","CANDY","CHOOSE","THINK","MORAL","PAIN","FEELINGS","SCARED","HUNGRY","P.SEX","O.SEX","OLDER","Audio_file","Comments")]

#Rename all variables so that they have the same names across conditions
names(WL1.A) <- c("ResponseID","StartDate","Finished","Condition","AccurateRobot","Subject","Sex","DOB","DOT","Fam1","Fam1_TEXT","Fam2","Fam2_TEXT","Fam3","Fam3_TEXT","Fam4","Fam4_TEXT","EJ1","Ask1A","Ask1A_TEXT","Ask1B","Ask1C","Ask2A","Ask2A_TEXT","Ask2B","Ask2C","Ask3A","Ask3A_TEXT","Ask3B","Ask3C","Ask4A","Ask4A_TEXT","Ask4B","Ask4C","EJ2","WHYCHOOSE","WHY","CANDY","CHOOSE","THINK","MORAL","PAIN","FEELINGS","SCARED","HUNGRY","P.SEX","O.SEX","OLDER","Audio_file","Comments")

names(WL1.B) <- c("ResponseID","StartDate","Finished","Condition","AccurateRobot","Subject","Sex","DOB","DOT","Fam1","Fam1_TEXT","Fam2","Fam2_TEXT","Fam3","Fam3_TEXT","Fam4","Fam4_TEXT","EJ1","Ask1A","Ask1A_TEXT","Ask1B","Ask1C","Ask2A","Ask2A_TEXT","Ask2B","Ask2C","Ask3A","Ask3A_TEXT","Ask3B","Ask3C","Ask4A","Ask4A_TEXT","Ask4B","Ask4C","EJ2","WHYCHOOSE","WHY","CANDY","CHOOSE","THINK","MORAL","PAIN","FEELINGS","SCARED","HUNGRY","P.SEX","O.SEX","OLDER","Audio_file","Comments")

names(WL1.C) <- c("ResponseID","StartDate","Finished","Condition","AccurateRobot","Subject","Sex","DOB","DOT","Fam1","Fam1_TEXT","Fam2","Fam2_TEXT","Fam3","Fam3_TEXT","Fam4","Fam4_TEXT","EJ1","Ask1A","Ask1A_TEXT","Ask1B","Ask1C","Ask2A","Ask2A_TEXT","Ask2B","Ask2C","Ask3A","Ask3A_TEXT","Ask3B","Ask3C","Ask4A","Ask4A_TEXT","Ask4B","Ask4C","EJ2","WHYCHOOSE","WHY","CANDY","CHOOSE","THINK","MORAL","PAIN","FEELINGS","SCARED","HUNGRY","P.SEX","O.SEX","OLDER","Audio_file","Comments")

names(WL1.D) <- c("ResponseID","StartDate","Finished","Condition","AccurateRobot","Subject","Sex","DOB","DOT","Fam1","Fam1_TEXT","Fam2","Fam2_TEXT","Fam3","Fam3_TEXT","Fam4","Fam4_TEXT","EJ1","Ask1A","Ask1A_TEXT","Ask1B","Ask1C","Ask2A","Ask2A_TEXT","Ask2B","Ask2C","Ask3A","Ask3A_TEXT","Ask3B","Ask3C","Ask4A","Ask4A_TEXT","Ask4B","Ask4C","EJ2","WHYCHOOSE","WHY","CANDY","CHOOSE","THINK","MORAL","PAIN","FEELINGS","SCARED","HUNGRY","P.SEX","O.SEX","OLDER","Audio_file","Comments")

#Add a new variable to each data set which contains the condition name for each participant
WL1.A$Order = "A"
WL1.B$Order = "B"
WL1.C$Order = "C"
WL1.D$Order = "D"

#Combine all data into one dataset
WL1 <- rbind(WL1.A,WL1.B,WL1.C,WL1.D)
```

```{r WL1_preprocessing}
#Set all missing values to NA
WL1[ WL1 == "" ] = NA
WL1[ WL1 == -99 ] = NA


WL1[WL1$Subject == "010AnA",]$DOB = '06/13/2012' #error in experimenter data entry

#Convert categorical variables to factors
WL1$AccurateRobot = factor(WL1$AccurateRobot)
WL1$EJ1 = factor(WL1$EJ1)
WL1$EJ2 = factor(WL1$EJ2)

WL1$Ask1B = factor(WL1$Ask1B)
WL1$Ask2B = factor(WL1$Ask2B)
WL1$Ask3B = factor(WL1$Ask3B)
WL1$Ask4B = factor(WL1$Ask4B)

WL1$Ask1C = factor(WL1$Ask1C)
WL1$Ask2C = factor(WL1$Ask1C)
WL1$Ask3C = factor(WL1$Ask3C)
WL1$Ask4C = factor(WL1$Ask4C)
```

```{r WL1_variables}
#Convert date variables to a format that can be processed by R
WL1$DOB = mdy(WL1$DOB)
WL1$DOT = mdy(WL1$DOT)

#Calculate the age of each participant in months
WL1$Age = year(as.period(interval(WL1$DOB, WL1$DOT)))*12 + month(as.period(interval(WL1$DOB, WL1$DOT))) + day(as.period(interval(WL1$DOB, WL1$DOT)))/30

WL1$AgeYears = WL1$Age/12

#Calculate whether children accurately answered all familiarization trials.
WL1$Fam.Match = ifelse(WL1$Fam1=="Brush",1,0) + ifelse(WL1$Fam2=="Doll",1,0) + ifelse(WL1$Fam3=="Ball",1,0) + ifelse(WL1$Fam4=="Bear",1,0)

#Calculate the proportion of answers where children accurately determined which robot was bad at naming the familiar objects 
WL1$EJ1.Match = ifelse(WL1$EJ1!=WL1$AccurateRobot,1,0)
WL1$EJ2.Match = ifelse(WL1$EJ2!=WL1$AccurateRobot,1,0)
WL1$EJ.Match = rowMeans(WL1[c('EJ1.Match','EJ2.Match')],na.rm=T)
WL1$EJ.Match[is.nan(WL1$EJ.Match)]=NA

WL1$EJ1.Purple = ifelse(WL1$EJ1!="Purple",1,0)
WL1$EJ2.Purple = ifelse(WL1$EJ2!="Purple",1,0)
WL1$EJ.Purple = rowMeans(WL1[c('EJ1.Purple','EJ2.Purple')],na.rm=T)
WL1$EJ.Purple[is.nan(WL1$EJ.Purple)]=NA

WL1$EJ1.Orange = ifelse(WL1$EJ1!="Orange",1,0)
WL1$EJ2.Orange = ifelse(WL1$EJ2!="Orange",1,0)
WL1$EJ.Orange = rowMeans(WL1[c('EJ1.Orange','EJ2.Orange')],na.rm=T)
WL1$EJ.Orange[is.nan(WL1$EJ.Orange)]=NA

#Calculate the proportion of answers where children said they would ask the accurate robot for the name of the novel object
WL1$Ask1B.Match = ifelse(WL1$Ask1B==WL1$AccurateRobot,1,0)
WL1$Ask2B.Match = ifelse(WL1$Ask2B==WL1$AccurateRobot,1,0)
WL1$Ask3B.Match = ifelse(WL1$Ask3B==WL1$AccurateRobot,1,0)
WL1$Ask4B.Match = ifelse(WL1$Ask4B==WL1$AccurateRobot,1,0)
WL1$Ask.Match = rowMeans(WL1[c('Ask1B.Match','Ask2B.Match','Ask3B.Match','Ask4B.Match')],na.rm=T)
WL1$Ask.Match[is.nan(WL1$Ask.Match)]=NA

WL1$Ask1B.Purple = ifelse(WL1$Ask1B=='Purple',1,0)
WL1$Ask2B.Purple = ifelse(WL1$Ask2B=='Purple',1,0)
WL1$Ask3B.Purple = ifelse(WL1$Ask3B=='Purple',1,0)
WL1$Ask4B.Purple = ifelse(WL1$Ask4B=='Purple',1,0)
WL1$Ask.Purple = rowMeans(WL1[c('Ask1B.Purple','Ask2B.Purple','Ask3B.Purple','Ask4B.Purple')],na.rm=T)
WL1$Ask.Purple[is.nan(WL1$Ask.Purple)]=NA

WL1$Ask1B.Orange = ifelse(WL1$Ask1B=='Orange',1,0)
WL1$Ask2B.Orange = ifelse(WL1$Ask2B=='Orange',1,0)
WL1$Ask3B.Orange = ifelse(WL1$Ask3B=='Orange',1,0)
WL1$Ask4B.Orange = ifelse(WL1$Ask4B=='Orange',1,0)
WL1$Ask.Orange = rowMeans(WL1[c('Ask1B.Orange','Ask2B.Orange','Ask3B.Orange','Ask4B.Orange')],na.rm=T)
WL1$Ask.Orange[is.nan(WL1$Ask.Orange)]=NA

WL1$Ask.bin = factor(ifelse(WL1$Ask.Match <= mean(WL1$Ask.Match,na.rm=T), 0, 1))

#Calculate the proportion of answers where children chose the same name that the accurate robot chose
WL1$Ask1C.Match = ifelse(WL1$Ask1C==WL1$AccurateRobot,1,0)
WL1$Ask2C.Match = ifelse(WL1$Ask2C==WL1$AccurateRobot,1,0)
WL1$Ask3C.Match = ifelse(WL1$Ask3C==WL1$AccurateRobot,1,0)
WL1$Ask4C.Match = ifelse(WL1$Ask4C==WL1$AccurateRobot,1,0)
WL1$Word.Match = rowMeans(WL1[c('Ask1C.Match','Ask2C.Match','Ask3C.Match','Ask4C.Match')],na.rm=T)
WL1$Word.Match[is.nan(WL1$Ask.Match)]=NA

WL1$Ask1C.Purple = ifelse(WL1$Ask1C=='Purple',1,0)
WL1$Ask2C.Purple = ifelse(WL1$Ask2C=='Purple',1,0)
WL1$Ask3C.Purple = ifelse(WL1$Ask3C=='Purple',1,0)
WL1$Ask4C.Purple = ifelse(WL1$Ask4C=='Purple',1,0)
WL1$Word.Purple = rowMeans(WL1[c('Ask1C.Purple','Ask2C.Purple','Ask3C.Purple','Ask4C.Purple')],na.rm=T)
WL1$Word.Purple[is.nan(WL1$Ask.Purple)]=NA

WL1$Ask1C.Orange = ifelse(WL1$Ask1C=='Orange',1,0)
WL1$Ask2C.Orange = ifelse(WL1$Ask2C=='Orange',1,0)
WL1$Ask3C.Orange = ifelse(WL1$Ask3C=='Orange',1,0)
WL1$Ask4C.Orange = ifelse(WL1$Ask4C=='Orange',1,0)
WL1$Word.Orange = rowMeans(WL1[c('Ask1C.Orange','Ask2C.Orange','Ask3C.Orange','Ask4C.Orange')],na.rm=T)
WL1$Word.Orange[is.nan(WL1$Ask.Orange)]=NA

WL1$Word.bin = factor(ifelse(WL1$Word.Match <= mean(WL1$Word.Match,na.rm=T), 0, 1))

WL1$Total = rowMeans(WL1[c('EJ1.Match','EJ2.Match','Ask1B.Match','Ask2B.Match','Ask3B.Match','Ask4B.Match','Ask1C.Orange','Ask2C.Orange','Ask3C.Orange','Ask4C.Orange')],na.rm=T)

WL1$Total.red = rowMeans(WL1[c('Ask1B.Match','Ask2B.Match','Ask3B.Match','Ask4B.Match','Ask1C.Orange','Ask2C.Orange','Ask3C.Orange','Ask4C.Orange')],na.rm=T)

WL1$Total.bin = factor(ifelse(WL1$Total <= mean(WL1$Total,na.rm=T), 0, 1))
```

There were `r sum(grepl("No Show",WL1$Comments))+sum(grepl("No show",WL1$Comments))` no shows.
There were `r sum(grepl("Cancelled",WL1$Comments))+sum(grepl("cancelled",WL1$Comments))+sum(grepl("Canceled",WL1$Comments))+sum(grepl("canceled",WL1$Comments))` cancelled appointments
There were `r sum(grepl("Fuss out",WL1$Comments))+sum(grepl("fuss out",WL1$Comments))` fuss outs.

```{r WL1_predictors}
#Recode perceptions of agency and experience questions
WL1$THINK.score = ifelse(WL1$THINK=="No",0,ifelse(WL1$THINK=="A little bit",1,ifelse(WL1$THINK=="A medium amount",2,ifelse(WL1$THINK=="A lot",3,NA))))
WL1$MORAL.score = ifelse(WL1$MORAL=="No",0,ifelse(WL1$MORAL=="A little bit",1,ifelse(WL1$MORAL=="A medium amount",2,ifelse(WL1$MORAL=="A lot",3,NA))))
WL1$CHOOSE.score = ifelse(WL1$CHOOSE=="No",0,ifelse(WL1$CHOOSE=="A few things",1,ifelse(WL1$CHOOSE=="A medium amount of things",2,ifelse(WL1$CHOOSE=="A lot of things",3,NA))))
WL1$PAIN.score = ifelse(WL1$PAIN=="No",0,ifelse(WL1$PAIN=="A little bit",1,ifelse(WL1$PAIN=="A medium amount",2,ifelse(WL1$PAIN=="A lot",3,NA))))
WL1$SCARED.score = ifelse(WL1$SCARED=="No",0,ifelse(WL1$SCARED=="A little bit",1,ifelse(WL1$SCARED=="A medium amount",2,ifelse(WL1$SCARED=="A lot",3,NA))))
WL1$HUNGRY.score = ifelse(WL1$HUNGRY=="No",0,ifelse(WL1$HUNGRY=="A little bit",1,ifelse(WL1$HUNGRY=="A medium amount",2,ifelse(WL1$HUNGRY=="A lot",3,NA))))

#Calculate aggregates of children's perceptions of the robots' agency and experience
WL1$AgIndex = (WL1$THINK.score + WL1$MORAL.score + WL1$CHOOSE.score)/3
WL1$ExpIndex = (WL1$PAIN.score + WL1$SCARED.score + WL1$HUNGRY.score)/3
WL1$MindIndex = (WL1$PAIN.score + WL1$SCARED.score + WL1$HUNGRY.score+WL1$THINK.score + WL1$MORAL.score + WL1$CHOOSE.score)/6
WL1$AgIndex.cent = scale(WL1$AgIndex,center=T,scale=T)
WL1$ExpIndex.cent = scale(WL1$ExpIndex,center=T,scale=T)
WL1$Age.cent = scale(WL1$Age,center=T,scale=T)
WL1$MindIndex.cent = scale(WL1$MindIndex,center=T,scale=T)
```

```{r WL1_no_shows}
WL1 = WL1[!is.na(WL1$Fam.Match),]
WL1 = WL1[WL1$Subject!="Test",]
WL1 = WL1[WL1$Subject!="Test2",]

WL1$Subject = factor(WL1$Subject)
WL1 = WL1[!is.na(WL1$Subject),]

#No Show
WL1 = WL1[!grepl("No show",WL1$Comments),]
WL1 = WL1[!grepl("Canceled right before study",WL1$Comments),]
```

```{r WL1_demographics}
filename <- "/Volumes/lsa-research01/ALL STUDIES/Current Studies/Word Learning/1.0/WL1 - Demographics.csv"
WL1_demo = read.csv(filename)

WL1_demo = WL1_demo[(WL1_demo$SubID %in% WL1$Subject),]
pander(summary(WL1_demo$Race_Ethnicity_Baby))
```
##Demographics
There are `r dim(WL1)[1]` participants.

The average age of the sample is `r round(mean(WL1$Age), digits = 2)` months.

The median age of the sample is `r round(median(WL1$Age), digits = 2)` months.

The minimum age of the sample is `r round(min(WL1$Age), digits = 2)` months.

The maximum age of the sample is `r round(max(WL1$Age), digits = 2)` months.

There are `r sum(WL1$Sex == "Female")` females in the sample.

The first date of test was `r min(WL1$DOT)`.

The most recent date of test was `r max(WL1$DOT)`.

```{r WL1_excluding}
#Non-native English Speaker
WL1 = WL1[which(WL1$Subject!="051TT"),] 
#Should not use data. Mom said his English is much weaker than his Slovak and he might not understand the questions

#Asked to end early
WL1 = WL1[!grepl("Fuss out",WL1$Comments),]
WL1 = WL1[!grepl("Quit early",WL1$Comments),]
WL1 = WL1[!grepl("Didn't answer any of the novel objects",WL1$Comments),]
WL1 = WL1[!grepl("Wouldn't answer novel object questions",WL1$Comments),]

#Parent interference
WL1 = WL1[!grepl("Very shy. Dad gave advice on how to answer.",WL1$Comments),]
```

1 participant was excluded for being a non-native english speaker.

4 participants asked to end early

1 participant had parent interference.

There are now `r dim(WL1)[1]` participants.

The average age of the sample is `r round(mean(WL1$Age), digits = 2)` months.

The median age of the sample is `r round(median(WL1$Age), digits = 2)` months.

The minimum age of the sample is `r round(min(WL1$Age), digits = 2)` months.

The maximum age of the sample is `r round(max(WL1$Age), digits = 2)` months.

There are `r sum(WL1$Sex == "Female")` females in the sample.

The first date of test was `r min(WL1$DOT)`.

The most recent date of test was `r max(WL1$DOT)`.

```{r WL1_descriptives}
#calculate summary statistics for age of sample
panderOptions("digits", 4)
pander(summary(WL1$Age), caption = 'Age(months)')
hist(WL1$Age,main='',xlab='Age(months)', col=color)

pander(summary(WL1$AgeYears), caption = 'Age(years)')
hist(WL1$AgeYears, main='',xlab='Age(years)', col=color)

#report how many participants completed each order of the survey
pander(table(WL1$Order),caption = 'Distribution by Order of Presentation')
```

##Performance during accuracy trials 
```{r WL1_accuracy_trials}
#report summary statistics for performance during familiarization/accuracy trials
pander(summary(WL1$Fam.Match))
hist(WL1$Fam.Match,main='',xlab='Num correct', col=color)
pander(table(WL1$Fam.Match),caption='Participant Count by Number of Trials Correct')
```

```{r WL1_familiarization_error}
#Remove all participants that failed to correctly answer all four familiarization trials
WL1 = WL1[which(WL1$Fam.Match==4),]
#WL1 = WL1[which(WL1$EJ1.Match==1),]

pander(table(WL1$Order),caption = 'Distribution by Order of Presentation after removing for familiarization')
```

Now there are `r dim(WL1)[1]` participants after removing for familiarization errors. 

There are `r dim(WL1)[1]` participants.

The average age of the sample is `r round(mean(WL1$Age), digits = 2)` months.

The median age of the sample is `r round(median(WL1$Age), digits = 2)` months.

The minimum age of the sample is `r round(min(WL1$Age), digits = 2)` months.

The maximum age of the sample is `r round(max(WL1$Age), digits = 2)` months.

There are `r sum(WL1$Sex == "Female")` females in the sample.

The first date of test was `r min(WL1$DOT)`.

The most recent date of test was `r max(WL1$DOT)`.

```{r WL1_exploration}
t.test(WL1$Total~WL1$Sex)

pander(summary(aov(Total~Order, data=WL1)))

pander(summary(glm(Total~Order+Age, data=WL1)))

pander(summary(glm(Total~Order+AgIndex, data=WL1)))

pander(summary(WL1$Total), caption="Total Correct Breakdown")
pander(sd(WL1$Total), caption="Total Correct Standard Deviation")
```

#Comparisons with chance for three test questions.
```{r WL1_performance, fig.height=8,fig.width=8}

#Report summary statistics for accuracy on judgment questions
pander(summary(WL1$EJ1.Match), caption='Proportion of Explicit Judgment Questions Correct')
hist(WL1$EJ1.Match,main='',xlab='Proportion of explicit judgment correct', col=color)

#Report summary statistics for accuracy on ask questions
pander(summary(WL1$Ask.Match),caption='Proportion of Ask Questions correct')
hist(WL1$Ask.Match,main='',xlab='Proportion of Ask Questions correct',col=color)

#Report summary statistics for accuracy on endorse questions
pander(summary(WL1$Word.Match), caption = 'Proportion of Endorsement Questions correct')
hist(WL1$Word.Match, main='',xlab='Proportion of Endorsement Questions correct',col=color)

pander(summary(WL1$Total), caption = 'Performance across all questions')
hist(WL1$Total, main='',xlab='Performance',col=color)

#Compare performance to chance guessing
EJ.ttest = t.test(WL1$EJ1.Match,mu=.5) # Ho: mu=0.5
Ask.ttest = t.test(WL1$Ask.Match,mu=.5)
Word.ttest = t.test(WL1$Word.Match,mu=.5)

chance.table = data.frame(Question = c('Explicit judgment','Ask','Endorse'), 
                          Proportion = c(
                            paste(round(EJ.ttest$estimate,2),
                                  '(',round(std.error(WL1$EJ.Match),2),')',sep=''), 
                            paste(round(Ask.ttest$estimate,2),
                                  '(',round(std.error(WL1$Ask.Match),2),')',sep=''),
                            paste(round(Word.ttest$estimate,2),
                                  '(',round(std.error(WL1$Word.Match),2),')',sep='')), 
                          't(df)' = c(
                            paste(round(EJ.ttest$statistic,2),
                                  '(',round(EJ.ttest$parameter,2),')',sep=''), 
                            paste(round(Ask.ttest$statistic,2),
                                  '(',round(Ask.ttest$parameter,2),')',sep=''),
                            paste(round(Word.ttest$statistic,2),
                                  '(',round(Word.ttest$parameter,2),')',sep='')),
                          '95%CI' = c(paste(round(EJ.ttest$conf.int[1],2),
                                             round(EJ.ttest$conf.int[2],2),sep=","),
                                       paste(round(Ask.ttest$conf.int[1],2),
                                             round(Ask.ttest$conf.int[2],2),sep=","),
                                       paste(round(Word.ttest$conf.int[1],2),
                                             round(Word.ttest$conf.int[2],2),sep=",")),
                          'p' = c(paste(round(EJ.ttest$p.value,4)),
                                  paste(round(Ask.ttest$p.value,4)),
                                  paste(round(Word.ttest$p.value,4)))
                          )

pander(chance.table,style = 'rmarkdown')

WL1.perf = WL1[c("EJ1.Match","Ask.Match","Word.Match","Subject")]
names(WL1.perf) = c("Judgment","Ask","Endorse","Participant")
perf = melt(WL1.perf,id='Participant')
names(perf) = c("Participant","Question Type","Proportion")

performance <- aggregate(perf$Proportion,
    by = list("Question Type" = perf$`Question Type`),
    FUN = function(x) c(mean = mean(x,na.rm=T), sd = sd(x,na.rm=T), n = length(x)))

performance <- do.call(data.frame, performance)
performance$CI <- qt(0.975,df=performance$x.n-1)*performance$x.sd/sqrt(performance$x.n)

performance = performance[c("Question.Type","x.mean","CI")]
names(performance) = c("Question Type","Proportion","CI")

ggplot(data = performance, aes(x = `Question Type`, y = Proportion, fill = `Question Type`)) + 
  guides(fill=FALSE) + 
  scale_fill_manual(values=wes_palette(n=3, name=wesanderson)) +
  geom_bar(width = .5, position=position_dodge(), stat="identity") + 
  geom_errorbar(aes(ymin=performance$Proportion-performance$CI, ymax=performance$Proportion+performance$CI),
                        width=.1,
                        size = 1.5, # Width of the error bars
                        position=position_dodge(.65)) + 
  theme(text = element_text(size=38,family="Corbel",colour="white"),
        axis.text.x = element_text(size=32,colour="white"),
        axis.title.x = element_text(vjust=0.1,colour="white"),
        axis.text.y=element_text(angle=90, hjust=.5, size=32,colour="white"),
        axis.title.y=element_text(margin=margin(0,20,0,0),colour="white"),
        plot.background = element_rect(fill = "transparent", colour = NA),
        panel.grid.major.x = element_blank())  + 
  labs(y="Proportion of Correct Responses", title = "Social Robots") + 
  #scale_y_continuous(limits = c(0, 1)) + 
  geom_hline(aes(yintercept=.5),size=1.5)# +
  #scale_y_continuous(expand = c(0, 0), limits = c(0,1))

t.test(WL1$EJ.Purple,mu=.5) # Ho: mu=0.5
t.test(WL1$Ask.Purple,mu=.5)
t.test(WL1$Word.Purple,mu=.5)
t.test(WL1$EJ.Orange,mu=.5) # Ho: mu=0.5
t.test(WL1$Ask.Orange,mu=.5)
t.test(WL1$Word.Orange,mu=.5)

#For future rmarkdown pdf use
# \begin{center}
#   \begin{tabular}{lccc}
#     \hline
#     Question & Proportion & t(`r EJ.ttest$parameter`) & 95\% CI\\
#     \hline
#     'Explicit judgment' & `r round(EJ.ttest$estimate,2)`(`r round(std.error(WL1$EJ.Match),2)`) & `r round(EJ.ttest$statistic,2)` & `r round(EJ.ttest$conf.int,2)` \\
#     Ask & `r round(Ask.ttest$estimate,2)`(`r round(std.error(WL1$Ask.Match),2)`) & `r round(Ask.ttest$statistic,2)` & `r round(Ask.ttest$conf.int,2)` \\
#     Endorse & `r round(Word.ttest$estimate,2)`(`r round(std.error(WL1$Word.Match),2)`) & `r round(Word.ttest$statistic,2)` & `r round(Word.ttest$conf.int,2)` \\
#   \end{tabular}
# \end{center}
```


```{r WL1_correlations_IV, include=FALSE}
#Calculate correlations between aggregates and test questions

#Agency and experience
cor.test(WL1$AgIndex,WL1$ExpIndex)
ggplot(WL1, aes(AgIndex,ExpIndex)) + geom_point(position = position_jitter(w = 0.2, h = 0.2)) + geom_smooth(method=lm)

#Age and experience
cor.test(WL1$Age,WL1$ExpIndex)
ggplot(WL1, aes(Age,ExpIndex)) + geom_point(position = position_jitter(w = 0.2, h = 0.2)) + geom_smooth(method=lm)

#Ask and experience
cor.test(WL1$Ask.Match,WL1$ExpIndex)
ggplot(WL1, aes(ExpIndex,Ask.Match)) + geom_point(position = position_jitter(w = 0.2, h = 0.2)) + geom_smooth(method=lm)

#Word and experience
cor.test(WL1$Word.Match,WL1$ExpIndex)
ggplot(WL1, aes(ExpIndex,Ask.Match)) + geom_point(position = position_jitter(w = 0.2, h = 0.2)) + geom_smooth(method=lm)

#Age and agency
cor.test(WL1$Age,WL1$AgIndex)
ggplot(WL1, aes(Age,AgIndex)) + geom_point(position = position_jitter(w = 0.2, h = 0.2)) + geom_smooth(method=lm)

#Ask and agency
cor.test(WL1$Ask.Match,WL1$AgIndex)
ggplot(WL1, aes(AgIndex,Ask.Match)) + geom_point(position = position_jitter(w = 0.2, h = 0.2)) + geom_smooth(method=lm)

#Word and agency
cor.test(WL1$Word.Match,WL1$AgIndex)
ggplot(WL1, aes(AgIndex,Word.Match)) + geom_point(position = position_jitter(w = 0.2, h = 0.2)) + geom_smooth(method=lm)
```

#Predicting Total Correct
```{r WL1_correlations}
#Agency

cor.test(WL1$Total,WL1$AgIndex)
AgencyTotal.Data = data.frame(Endorsement = WL1$Total, Agency = WL1$AgIndex)

ggplot(AgencyTotal.Data, aes(Agency,Endorsement)) + 
  geom_point(position = position_jitter(w = 0.05, h = 0.05), size=4, color=wes_palette(n=5, name=wesanderson)[1]) + 
  geom_smooth(method=lm, colour=wes_palette(n=5, name=wesanderson)[5], size=3) +
  scale_color_manual(values=wes_palette(n=1, name=wesanderson)) + 
  labs(y="Proportion of Correct Responses") + 
  theme(text = element_text(size=36,family="Corbel",colour="white"),
        axis.text.x = element_text(size=32,colour="white"),
        axis.title.x = element_text(vjust=0.1,colour="white"),
        axis.text.y=element_text(angle=90, hjust=.5, size=32,colour="white"),
        axis.title.y=element_text(margin=margin(0,20,0,0),colour="white"),
        plot.background = element_rect(fill = "transparent", colour = NA),
        plot.margin = margin(10, 10, 10, 12))

#Experience
cor.test(WL1$Total,WL1$ExpIndex)
ExpTotal.Data = data.frame(Endorsement = WL1$Total, Experience = WL1$ExpIndex)

ExpPlot = ggplot(ExpTotal.Data, aes(Experience,Endorsement))
ExpPlot +  geom_point(position = position_jitter(w = 0.2, h = 0.2)) + geom_smooth(method=lm)
```

##Regression Analyses
```{r WL1_regressions}
#assess which predictors predict responses to test questions
#summary(glm(Ask.Match~ExpIndex.cent+AgIndex.cent,data=WL1))
#summary(glm(Word.Match~ExpIndex.cent*AgIndex.cent,data=WL1))
summary(glm(Total~ExpIndex.cent+AgIndex.cent,data=WL1))
lm.beta(glm(Total~ExpIndex.cent+AgIndex.cent,data=WL1))

summary(glm(Total~ExpIndex.cent+AgIndex.cent+Age.cent,data=WL1))

summary(glm(Total~ExpIndex.cent+AgIndex.cent+Age.cent+Sex,data=WL1))

summary(glm(Total~ExpIndex.cent+AgIndex.cent+Age.cent+Sex+Order,data=WL1))
pander(summary(lm(Total~ExpIndex.cent+AgIndex.cent+Age.cent+Sex+Order,data=WL1)))
lm.beta(glm(Total~ExpIndex.cent+AgIndex.cent+Age.cent+Sex+Order,data=WL1))

summary(glm(Total~AgIndex.cent+Age.cent,data=WL1))

#plot(WL1$Total~WL1$AgIndex.cent,col=color,xlab='Agency',ylab='Performance',main="",lwd=4)
#abline(lm(Total~AgIndex.cent+Age.cent+Sex,data=WL1),col=color,lwd=4)

summary(glm(Total.bin~ExpIndex.cent+AgIndex.cent+Age.cent+Sex,data=WL1,family="binomial"))

```

```{r WL1_regression_mind}

#assess which predictors predict responses to test questions

summary(glm(Total~MindIndex.cent,data=WL1))

summary(glm(Total~MindIndex.cent+Age.cent,data=WL1))

summary(glm(Total~MindIndex.cent+Age.cent+Sex,data=WL1))
summary(glm(Total~MindIndex.cent+Sex,data=WL1))
```

```{r WL1_mind_plot}
WL1.mind = WL1[c("AgIndex","ExpIndex","Subject")]
names(WL1.mind) = c("Agency","Experience","Participant")
mind = melt(WL1.mind,id='Participant')
names(mind) = c("Participant","Attributions of Mind","Responses")

performance <- aggregate(mind$Responses,
    by = list("Attributions of Mind" = mind$`Attributions of Mind`),
    FUN = function(x) c(mean = mean(x,na.rm=T), sd = sd(x,na.rm=T), n = length(x)))

performance <- do.call(data.frame, performance)
performance$CI <- qt(0.975,df=performance$x.n-1)*performance$x.sd/sqrt(performance$x.n)

performance = performance[c("Attributions.of.Mind","x.mean","CI")]
names(performance) = c("Attributions of Mind","Responses","CI")

ggplot(data = performance, aes(x = `Attributions of Mind`, y = `Responses`, fill = `Attributions of Mind`)) + 
  guides(fill=FALSE) + 
  geom_bar(width = .5, position=position_dodge(), stat="identity") + 
  geom_errorbar(aes(ymin=performance$Responses-performance$CI, ymax=performance$Responses+performance$CI),
                width=.1,
                size = 1.2, # Width of the error bars
                position=position_dodge(.65)) + 
  labs(y="Responses") +
  theme(text = element_text(size=28,family="Corbel"),
        axis.text.x = element_text(size=20),
        axis.title.x = element_text(vjust=0.1),
        axis.text.y=element_text(angle=90, hjust=.5, size=16),
        axis.title.y=element_text(margin=margin(0,20,0,0),size=24))
```

#Word Learning 2: Control Study
```{r WL2_import}
source("~/Dropbox/Research/Michigan/Dissertation - Robots/Word Learning/Private/WL2_data.R")
```

```{r WL2_formatting}
#Clean the data set

#Subset the data set by condition (i.e., by the order in which the robots are presented and by which robot is accurate)
WL2.A <- subset(qualtrics.WL2, Condition==1 & AccurateRobot=='Purple')
WL2.B <- subset(qualtrics.WL2, Condition==2 & AccurateRobot=='Purple')
WL2.C <- subset(qualtrics.WL2, Condition==1 & AccurateRobot=='Orange')
WL2.D <- subset(qualtrics.WL2, Condition==2 & AccurateRobot=='Orange')

#Each condition of the survey has different question names for the same questions. 
#Remove all unused variable names from each condition

WL2.A <- WL2.A[, c("ResponseID","StartDate","Finished","Assent","Condition","AccurateRobot","Subject","Sex","DOB","EXP","Fam1.A","Fam1.A_TEXT","Fam2.A","Fam2.A_TEXT","Fam3.A","Fam3.A_TEXT","Fam4.A","Fam4.A_TEXT","EJ1.A","Ask1A.AC","Ask1A.AC_TEXT","Ask1B.AC","Ask1C.AC","Ask2A.AC","Ask2A.AC_TEXT","Ask2B.AC","Ask2C.AC","Ask3A.AC","Ask3A.AC_TEXT","Ask3B.AC","Ask3C.AC","Ask4A.AC","Ask4A.AC_TEXT","Ask4B","Ask4C","EJ2.AC","WHYCHOOSE","WHY","CANDY","CHOOSE","THINK","MORAL","PAIN","FEELINGS","SCARED","HUNGRY","P.SEX","O.SEX","OLDER","Audio_File","Comments")] 

WL2.B <- WL2.B[, c("ResponseID","StartDate","Finished","Assent","Condition","AccurateRobot","Subject","Sex","DOB","EXP","Fam1.B","Fam1.B_TEXT","Fam2.B","Fam2.B_TEXT","Fam3.B","Fam3.B_TEXT","Fam4.B","Fam4.B_TEXT","EJ1.B","Ask1A.BD","Ask1A.BD_TEXT","Ask1B.BD","Ask1C.BD","Ask2A.BD","Ask2A.BD_TEXT","Ask2B.Bd","Ask2C.BD","Ask3A.BD","Ask3A.BD_TEXT","Ask3B.BD","Ask3C.BD","Ask4A.BD","Ask4A.BD_TEXT","Ask4B.BD","Ask4C.BD","EJ2","WHYCHOOSE","WHY","CANDY","CHOOSE","THINK","MORAL","PAIN","FEELINGS","SCARED","HUNGRY","P.SEX","O.SEX","OLDER","Audio_File","Comments")]

WL2.C <- WL2.C[, c("ResponseID","StartDate","Finished","Assent","Condition","AccurateRobot","Subject","Sex","DOB","EXP","Fam1.C","Fam1.C_TEXT","Fam2.C","Fam2.C_TEXT","Fam3.C","Fam3.C_TEXT","Fam4.C","Fam4.C_TEXT","EJ1.C","Ask1A.AC","Ask1A.AC_TEXT","Ask1B.AC","Ask1C.AC","Ask2A.AC","Ask2A.AC_TEXT","Ask2B.AC","Ask2C.AC","Ask3A.AC","Ask3A.AC_TEXT","Ask3B.AC","Ask3C.AC","Ask4A.AC","Ask4A.AC_TEXT","Ask4B","Ask4C","EJ2.AC","WHYCHOOSE","WHY","CANDY","CHOOSE","THINK","MORAL","PAIN","FEELINGS","SCARED","HUNGRY","P.SEX","O.SEX","OLDER","Audio_File","Comments")] 

WL2.D <- WL2.D[, c("ResponseID","StartDate","Finished","Assent","Condition","AccurateRobot","Subject","Sex","DOB","EXP","Fam1.D","Fam1.D_TEXT","Fam2.D","Fam2.D_TEXT","Fam3.D","Fam3.D_TEXT","Fam4.D","Fam4.D_TEXT","EJ1.D","Ask1A.BD","Ask1A.BD_TEXT","Ask1B.BD","Ask1C.BD","Ask2A.BD","Ask2A.BD_TEXT","Ask2B.Bd","Ask2C.BD","Ask3A.BD","Ask3A.BD_TEXT","Ask3B.BD","Ask3C.BD","Ask4A.BD","Ask4A.BD_TEXT","Ask4B.BD","Ask4C.BD","EJ2","WHYCHOOSE","WHY","CANDY","CHOOSE","THINK","MORAL","PAIN","FEELINGS","SCARED","HUNGRY","P.SEX","O.SEX","OLDER","Audio_File","Comments")]

#Rename all variables so that they have the same names across conditions
names(WL2.A) <- c("ResponseID","StartDate","Finished","Assent","Condition","AccurateRobot","Subject","Sex","DOB","EXP","Fam1","Fam1_TEXT","Fam2","Fam2_TEXT","Fam3","Fam3_TEXT","Fam4","Fam4_TEXT","EJ1","Ask1A","Ask1A_TEXT","Ask1B","Ask1C","Ask2A","Ask2A_TEXT","Ask2B","Ask2C","Ask3A","Ask3A_TEXT","Ask3B","Ask3C","Ask4A","Ask4A_TEXT","Ask4B","Ask4C","EJ2","WHYCHOOSE","WHY","CANDY","CHOOSE","THINK","MORAL","PAIN","FEELINGS","SCARED","HUNGRY","P.SEX","O.SEX","OLDER","Audio_file","Comments")

names(WL2.B) <- c("ResponseID","StartDate","Finished","Assent","Condition","AccurateRobot","Subject","Sex","DOB","EXP","Fam1","Fam1_TEXT","Fam2","Fam2_TEXT","Fam3","Fam3_TEXT","Fam4","Fam4_TEXT","EJ1","Ask1A","Ask1A_TEXT","Ask1B","Ask1C","Ask2A","Ask2A_TEXT","Ask2B","Ask2C","Ask3A","Ask3A_TEXT","Ask3B","Ask3C","Ask4A","Ask4A_TEXT","Ask4B","Ask4C","EJ2","WHYCHOOSE","WHY","CANDY","CHOOSE","THINK","MORAL","PAIN","FEELINGS","SCARED","HUNGRY","P.SEX","O.SEX","OLDER","Audio_file","Comments")

names(WL2.C) <- c("ResponseID","StartDate","Finished","Assent","Condition","AccurateRobot","Subject","Sex","DOB","EXP","Fam1","Fam1_TEXT","Fam2","Fam2_TEXT","Fam3","Fam3_TEXT","Fam4","Fam4_TEXT","EJ1","Ask1A","Ask1A_TEXT","Ask1B","Ask1C","Ask2A","Ask2A_TEXT","Ask2B","Ask2C","Ask3A","Ask3A_TEXT","Ask3B","Ask3C","Ask4A","Ask4A_TEXT","Ask4B","Ask4C","EJ2","WHYCHOOSE","WHY","CANDY","CHOOSE","THINK","MORAL","PAIN","FEELINGS","SCARED","HUNGRY","P.SEX","O.SEX","OLDER","Audio_file","Comments")

names(WL2.D) <- c("ResponseID","StartDate","Finished","Assent","Condition","AccurateRobot","Subject","Sex","DOB","EXP","Fam1","Fam1_TEXT","Fam2","Fam2_TEXT","Fam3","Fam3_TEXT","Fam4","Fam4_TEXT","EJ1","Ask1A","Ask1A_TEXT","Ask1B","Ask1C","Ask2A","Ask2A_TEXT","Ask2B","Ask2C","Ask3A","Ask3A_TEXT","Ask3B","Ask3C","Ask4A","Ask4A_TEXT","Ask4B","Ask4C","EJ2","WHYCHOOSE","WHY","CANDY","CHOOSE","THINK","MORAL","PAIN","FEELINGS","SCARED","HUNGRY","P.SEX","O.SEX","OLDER","Audio_file","Comments")

#Add a new variable to each data set which contains the condition name for each participant
WL2.A$Order = "A"
WL2.B$Order = "B"
WL2.C$Order = "C"
WL2.D$Order = "D"

#Combine all data into one dataset
WL2 <- rbind(WL2.A,WL2.B,WL2.C,WL2.D)
```

```{r WL2_preprocessing}
#Set all missing values to NA
WL2[ WL2 == "" ] = NA
WL2[ WL2 == -99 ] = NA

#Convert categorical variables to factors
WL2$AccurateRobot = factor(WL2$AccurateRobot)
WL2$EJ1 = factor(WL2$EJ1)
WL2$EJ2 = factor(WL2$EJ2)

WL2$Ask1B = factor(WL2$Ask1B)
WL2$Ask2B = factor(WL2$Ask2B)
WL2$Ask3B = factor(WL2$Ask3B)
WL2$Ask4B = factor(WL2$Ask4B)

WL2$Ask1C = factor(WL2$Ask1C)
WL2$Ask2C = factor(WL2$Ask1C)
WL2$Ask3C = factor(WL2$Ask3C)
WL2$Ask4C = factor(WL2$Ask4C)
```

```{r WL2_variables}
#Convert date variables to a format that can be processed by R
WL2$DOB = mdy(WL2$DOB)
WL2$DOT = as.Date(WL2$StartDate)

#Calculate the age of each participant in months
WL2$Age = year(as.period(interval(WL2$DOB, WL2$DOT)))*12 + month(as.period(interval(WL2$DOB, WL2$DOT))) + day(as.period(interval(WL2$DOB, WL2$DOT)))/30

WL2$AgeYears = WL2$Age/12

#Calculate whether children accurately answered all familiarization trials.
WL2$Fam.Match = ifelse(WL2$Fam1=="Brush",1,0) + ifelse(WL2$Fam2=="Doll",1,0) + ifelse(WL2$Fam3=="Ball",1,0) + ifelse(WL2$Fam4=="Bear",1,0)

#Calculate the proportion of answers where children accurately determined which robot was bad at naming the familiar objects 
WL2$EJ1.Match = ifelse(WL2$EJ1!=WL2$AccurateRobot,1,0)
WL2$EJ2.Match = ifelse(WL2$EJ2!=WL2$AccurateRobot,1,0)
WL2$EJ.Match = rowMeans(WL2[c('EJ1.Match','EJ2.Match')],na.rm=T)
WL2$EJ.Match[is.nan(WL2$EJ.Match)]=NA

WL2$EJ1.Purple = ifelse(WL2$EJ1!="Purple",1,0)
WL2$EJ2.Purple = ifelse(WL2$EJ2!="Purple",1,0)
WL2$EJ.Purple = rowMeans(WL2[c('EJ1.Purple','EJ2.Purple')],na.rm=T)
WL2$EJ.Purple[is.nan(WL2$EJ.Purple)]=NA

WL2$EJ1.Orange = ifelse(WL2$EJ1!="Orange",1,0)
WL2$EJ2.Orange = ifelse(WL2$EJ2!="Orange",1,0)
WL2$EJ.Orange = rowMeans(WL2[c('EJ1.Orange','EJ2.Orange')],na.rm=T)
WL2$EJ.Orange[is.nan(WL2$EJ.Orange)]=NA

#Calculate the proportion of answers where children said they would ask the accurate robot for the name of the novel object
WL2$Ask1B.Match = ifelse(WL2$Ask1B==WL2$AccurateRobot,1,0)
WL2$Ask2B.Match = ifelse(WL2$Ask2B==WL2$AccurateRobot,1,0)
WL2$Ask3B.Match = ifelse(WL2$Ask3B==WL2$AccurateRobot,1,0)
WL2$Ask4B.Match = ifelse(WL2$Ask4B==WL2$AccurateRobot,1,0)
WL2$Ask.Match = rowMeans(WL2[c('Ask1B.Match','Ask2B.Match','Ask3B.Match','Ask4B.Match')],na.rm=T)
WL2$Ask.Match[is.nan(WL2$Ask.Match)]=NA

WL2$Ask1B.Purple = ifelse(WL2$Ask1B=='Purple',1,0)
WL2$Ask2B.Purple = ifelse(WL2$Ask2B=='Purple',1,0)
WL2$Ask3B.Purple = ifelse(WL2$Ask3B=='Purple',1,0)
WL2$Ask4B.Purple = ifelse(WL2$Ask4B=='Purple',1,0)
WL2$Ask.Purple = rowMeans(WL2[c('Ask1B.Purple','Ask2B.Purple','Ask3B.Purple','Ask4B.Purple')],na.rm=T)
WL2$Ask.Purple[is.nan(WL2$Ask.Purple)]=NA

WL2$Ask1B.Orange = ifelse(WL2$Ask1B=='Orange',1,0)
WL2$Ask2B.Orange = ifelse(WL2$Ask2B=='Orange',1,0)
WL2$Ask3B.Orange = ifelse(WL2$Ask3B=='Orange',1,0)
WL2$Ask4B.Orange = ifelse(WL2$Ask4B=='Orange',1,0)
WL2$Ask.Orange = rowMeans(WL2[c('Ask1B.Orange','Ask2B.Orange','Ask3B.Orange','Ask4B.Orange')],na.rm=T)
WL2$Ask.Orange[is.nan(WL2$Ask.Orange)]=NA

WL2$Ask.bin = factor(ifelse(WL2$Ask.Match <= mean(WL2$Ask.Match,na.rm=T), 0, 1))

#Calculate the proportion of answers where children chose the same name that the accurate robot chose
WL2$Ask1C.Match = ifelse(WL2$Ask1C==WL2$AccurateRobot,1,0)
WL2$Ask2C.Match = ifelse(WL2$Ask2C==WL2$AccurateRobot,1,0)
WL2$Ask3C.Match = ifelse(WL2$Ask3C==WL2$AccurateRobot,1,0)
WL2$Ask4C.Match = ifelse(WL2$Ask4C==WL2$AccurateRobot,1,0)
WL2$Word.Match = rowMeans(WL2[c('Ask1C.Match','Ask2C.Match','Ask3C.Match','Ask4C.Match')],na.rm=T)
WL2$Word.Match[is.nan(WL2$Ask.Match)]=NA

WL2$Ask1C.Purple = ifelse(WL2$Ask1C=='Purple',1,0)
WL2$Ask2C.Purple = ifelse(WL2$Ask2C=='Purple',1,0)
WL2$Ask3C.Purple = ifelse(WL2$Ask3C=='Purple',1,0)
WL2$Ask4C.Purple = ifelse(WL2$Ask4C=='Purple',1,0)
WL2$Word.Purple = rowMeans(WL2[c('Ask1C.Purple','Ask2C.Purple','Ask3C.Purple','Ask4C.Purple')],na.rm=T)
WL2$Word.Purple[is.nan(WL2$Ask.Purple)]=NA

WL2$Ask1C.Orange = ifelse(WL2$Ask1C=='Orange',1,0)
WL2$Ask2C.Orange = ifelse(WL2$Ask2C=='Orange',1,0)
WL2$Ask3C.Orange = ifelse(WL2$Ask3C=='Orange',1,0)
WL2$Ask4C.Orange = ifelse(WL2$Ask4C=='Orange',1,0)
WL2$Word.Orange = rowMeans(WL2[c('Ask1C.Orange','Ask2C.Orange','Ask3C.Orange','Ask4C.Orange')],na.rm=T)
WL2$Word.Orange[is.nan(WL2$Ask.Orange)]=NA

WL2$Word.bin = factor(ifelse(WL2$Word.Match <= mean(WL2$Word.Match,na.rm=T), 0, 1))

WL2$Total = rowMeans(WL2[c('EJ1.Match','EJ2.Match','Ask1B.Match','Ask2B.Match','Ask3B.Match','Ask4B.Match','Ask1C.Orange','Ask2C.Orange','Ask3C.Orange','Ask4C.Orange')],na.rm=T)

WL2$Total.red = rowMeans(WL2[c('Ask1B.Match','Ask2B.Match','Ask3B.Match','Ask4B.Match','Ask1C.Orange','Ask2C.Orange','Ask3C.Orange','Ask4C.Orange')],na.rm=T)

WL2$Total.bin = factor(ifelse(WL2$Total <= mean(WL2$Total,na.rm=T), 0, 1))
```

There were `r sum(grepl("No Show",WL2$Comments))+sum(grepl("No show",WL2$Comments))` no shows.
There were `r sum(grepl("Cancelled",WL2$Comments))+sum(grepl("cancelled",WL2$Comments))+sum(grepl("Canceled",WL2$Comments))+sum(grepl("canceled",WL2$Comments))` cancelled appointments
There were `r sum(grepl("Fuss out",WL2$Comments))+sum(grepl("fuss out",WL2$Comments))` fuss outs.
There were `r sum(is.na(WL2$Assent))` children that did not assent.


```{r WL2_predictors}
#Recode perceptions of agency and experience questions
WL2$THINK.score = ifelse(WL2$THINK=="No",0,ifelse(WL2$THINK=="A little bit",1,ifelse(WL2$THINK=="A medium amount",2,ifelse(WL2$THINK=="A lot",3,NA))))
WL2$MORAL.score = ifelse(WL2$MORAL=="No",0,ifelse(WL2$MORAL=="A little bit",1,ifelse(WL2$MORAL=="A medium amount",2,ifelse(WL2$MORAL=="A lot",3,NA))))
WL2$CHOOSE.score = ifelse(WL2$CHOOSE=="No",0,ifelse(WL2$CHOOSE=="A few things",1,ifelse(WL2$CHOOSE=="A medium amount of things",2,ifelse(WL2$CHOOSE=="A lot of things",3,NA))))
WL2$PAIN.score = ifelse(WL2$PAIN=="No",0,ifelse(WL2$PAIN=="A little bit",1,ifelse(WL2$PAIN=="A medium amount",2,ifelse(WL2$PAIN=="A lot",3,NA))))
WL2$SCARED.score = ifelse(WL2$SCARED=="No",0,ifelse(WL2$SCARED=="A little bit",1,ifelse(WL2$SCARED=="A medium amount",2,ifelse(WL2$SCARED=="A lot",3,NA))))
WL2$HUNGRY.score = ifelse(WL2$HUNGRY=="No",0,ifelse(WL2$HUNGRY=="A little bit",1,ifelse(WL2$HUNGRY=="A medium amount",2,ifelse(WL2$HUNGRY=="A lot",3,NA))))

#Calculate aggregates of children's perceptions of the robots' agency and experience
WL2$AgIndex = (WL2$THINK.score + WL2$MORAL.score + WL2$CHOOSE.score)/3
WL2$ExpIndex = (WL2$PAIN.score + WL2$SCARED.score + WL2$HUNGRY.score)/3
WL2$MindIndex = (WL2$PAIN.score + WL2$SCARED.score + WL2$HUNGRY.score+WL2$THINK.score + WL2$MORAL.score + WL2$CHOOSE.score)/6
WL2$AgIndex.cent = scale(WL2$AgIndex,center=T,scale=T)
WL2$ExpIndex.cent = scale(WL2$ExpIndex,center=T,scale=T)
WL2$Age.cent = scale(WL2$Age,center=T,scale=T)
WL2$MindIndex.cent = scale(WL2$MindIndex,center=T,scale=T)
```

```{r WL2_no_shows}
WL2 = WL2[!is.na(WL2$Fam.Match),]
WL2 = WL2[WL2$Subject!="Test",]
WL2 = WL2[WL2$Subject!="Test2",]
WL2 = WL2[!is.na(WL2$Subject),]

#correction
WL2$Sex[grepl("The child is a girl, accidentally put that she was a boy",WL2$Comments)] = "Female"

```

##Demographics
```{r WL2_demographics}
filename <- "/Volumes/lsa-research01/ALL STUDIES/Current Studies/Word Learning/2.0/WL2 - Demographics.csv"
WL2_demo = read.csv(filename)

WL2_demo = WL2_demo[(WL2_demo$SubID %in% WL2$Subject),]
pander(summary(WL2_demo$Race_Ethnicity_Baby))
```

There are `r dim(WL2)[1]` participants.

The average age of the sample is `r round(mean(WL2$Age), digits = 2)` months.

The median age of the sample is `r round(median(WL2$Age), digits = 2)` months.

The minimum age of the sample is `r round(min(WL2$Age), digits = 2)` months.

The maximum age of the sample is `r round(max(WL2$Age), digits = 2)` months.

There are `r sum(WL2$Sex == "Female")` females in the sample.

The first date of test was `r min(WL2$DOT)`.

The most recent date of test was `r max(WL2$DOT)`.

```{r WL2_excluding}
#parent interference
WL2 = WL2[!grepl("Parent intereference",WL2$Comments),]

#non-native english speaker
WL2 = WL2[!grepl("Answered in foreign language. Very shy.",WL2$Comments),]

#ended early
WL2 = WL2[!grepl("They arrived 20 minutes late and the mother tried to rush the entire interview. Had to end early because the interview was taking too long for the mother's liking",WL2$Comments),]
WL2 = WL2[!grepl("Participant not focused at all, may have had a developmental disability",WL2$Comments),]
```


1 participant was excluded for being a non-native english speaker.

2 participants asked to end early

1 participant had parent interference.

There are now `r dim(WL2)[1]` participants.

The average age of the sample is `r round(mean(WL2$Age), digits = 2)` months.

The median age of the sample is `r round(median(WL2$Age), digits = 2)` months.

The minimum age of the sample is `r round(min(WL2$Age), digits = 2)` months.

The maximum age of the sample is `r round(max(WL2$Age), digits = 2)` months.

There are `r sum(WL2$Sex == "Female")` females in the sample.

The first date of test was `r min(WL2$DOT)`.

The most recent date of test was `r max(WL2$DOT)`.

```{r WL2_descriptives}
#calculate summary statistics for age of sample
panderOptions("digits", 4)
pander(summary(WL2$Age), caption = 'Age(months)')
hist(WL2$Age,main='',xlab='Age(months)', col=color)

pander(summary(WL2$AgeYears), caption = 'Age(years)')
hist(WL2$AgeYears, main='',xlab='Age(years)', col=color)

#report how many participants completed each order of the survey
pander(table(WL2$Order),caption = 'Distribution by Order of Presentation')
```

##Performance during accuracy trials 
```{r WL2_accuracy_trials}
#report summary statistics for performance during familiarization/accuracy trials
pander(summary(WL2$Fam.Match))
hist(WL2$Fam.Match,main='',xlab='Num correct', col=color)
pander(table(WL2$Fam.Match),caption='Participant Count by Number of Trials Correct')
```

```{r WL2_familiarization_error}
#Remove all participants that failed to correctly answer all four familiarization trials
WL2 = WL2[which(WL2$Fam.Match==4),]
#WL2 = WL2[which(WL2$EJ1.Match==1),]

pander(table(WL2$Order),caption = 'Distribution by Order of Presentation after removing for familiarization')
```

Now there are `r dim(WL2)[1]` participants after removing for familiarization errors. 

There are `r dim(WL2)[1]` participants.

The average age of the sample is `r round(mean(WL2$Age), digits = 2)` months.

The median age of the sample is `r round(median(WL2$Age), digits = 2)` months.

The minimum age of the sample is `r round(min(WL2$Age), digits = 2)` months.

The maximum age of the sample is `r round(max(WL2$Age), digits = 2)` months.

There are `r sum(WL2$Sex == "Female")` females in the sample.

The first date of test was `r min(WL2$DOT)`.

The most recent date of test was `r max(WL2$DOT)`.

```{r WL2_exploration}
#t.test(WL2$Total~WL2$Sex)

pander(summary(aov(Total~Order, data=WL2)))

pander(summary(glm(Total~Order+Age, data=WL2)))

pander(summary(glm(Total~Order+AgIndex, data=WL2)))

pander(summary(WL2$Total), caption="Total Correct Breakdown")
pander(sd(WL2$Total), caption="Total Correct Standard Deviation")
```

#Comparisons with chance for three test questions.
```{r WL2_performance, fig.height=8,fig.width=8}
#Report summary statistics for accuracy on judgment questions
pander(summary(WL2$EJ1.Match), caption='Proportion of Explicit Judgment Questions Correct')
hist(WL2$EJ1.Match,main='',xlab='Proportion of explicit judgment correct', col=color)

#Report summary statistics for accuracy on ask questions
pander(summary(WL2$Ask.Match),caption='Proportion of Ask Questions correct')
hist(WL2$Ask.Match,main='',xlab='Proportion of Ask Questions correct',col=color)

#Report summary statistics for accuracy on endorse questions
pander(summary(WL2$Word.Match), caption = 'Proportion of Endorsement Questions correct')
hist(WL2$Word.Match, main='',xlab='Proportion of Endorsement Questions correct',col=color)

pander(summary(WL2$Total), caption = 'Performance across all questions')
hist(WL2$Total, main='',xlab='Performance',col=color)

#Compare performance to chance guessing
EJ.ttest = t.test(WL2$EJ1.Match,mu=.5) # Ho: mu=0.5
Ask.ttest = t.test(WL2$Ask.Match,mu=.5)
Word.ttest = t.test(WL2$Word.Match,mu=.5)

chance.table = data.frame(Question = c('Explicit judgment','Ask','Endorse'), 
                          Proportion = c(
                            paste(round(EJ.ttest$estimate,2),
                                  '(',round(std.error(WL2$EJ.Match),2),')',sep=''), 
                            paste(round(Ask.ttest$estimate,2),
                                  '(',round(std.error(WL2$Ask.Match),2),')',sep=''),
                            paste(round(Word.ttest$estimate,2),
                                  '(',round(std.error(WL2$Word.Match),2),')',sep='')), 
                          't(df)' = c(
                            paste(round(EJ.ttest$statistic,2),
                                  '(',round(EJ.ttest$parameter,2),')',sep=''), 
                            paste(round(Ask.ttest$statistic,2),
                                  '(',round(Ask.ttest$parameter,2),')',sep=''),
                            paste(round(Word.ttest$statistic,2),
                                  '(',round(Word.ttest$parameter,2),')',sep='')),
                          '95%CI' = c(paste(round(EJ.ttest$conf.int[1],2),
                                             round(EJ.ttest$conf.int[2],2),sep=","),
                                       paste(round(Ask.ttest$conf.int[1],2),
                                             round(Ask.ttest$conf.int[2],2),sep=","),
                                       paste(round(Word.ttest$conf.int[1],2),
                                             round(Word.ttest$conf.int[2],2),sep=",")),
                          'p' = c(paste(round(EJ.ttest$p.value,4)),
                                  paste(round(Ask.ttest$p.value,4)),
                                  paste(round(Word.ttest$p.value,4)))
                          )

pander(chance.table,style = 'rmarkdown')

WL2.perf = WL2[c("EJ1.Match","Ask.Match","Word.Match","Subject")]
names(WL2.perf) = c("Judgment","Ask","Endorse","Participant")
perf = melt(WL2.perf,id='Participant')
names(perf) = c("Participant","Question Type","Proportion")

performance <- aggregate(perf$Proportion,
    by = list("Question Type" = perf$`Question Type`),
    FUN = function(x) c(mean = mean(x,na.rm=T), sd = sd(x,na.rm=T), n = length(x)))

performance <- do.call(data.frame, performance)
performance$CI <- qt(0.975,df=performance$x.n-1)*performance$x.sd/sqrt(performance$x.n)

performance = performance[c("Question.Type","x.mean","CI")]
names(performance) = c("Question Type","Proportion","CI")

ggplot(data = performance, aes(x = `Question Type`, y = Proportion, fill = `Question Type`)) + 
  guides(fill=FALSE) + 
  scale_fill_manual(values=wes_palette(n=3, name=wesanderson)) +
  geom_bar(width = .5, position=position_dodge(), stat="identity") + 
  geom_errorbar(aes(ymin=performance$Proportion-performance$CI, ymax=performance$Proportion+performance$CI),
                        width=.1,
                        size = 1.5, # Width of the error bars
                        position=position_dodge(.65)) + 
  labs(y="Proportion of Correct Responses", title = "Inanimate Machines") + 
  theme(text = element_text(size=38,family="Corbel",colour="white"),
        axis.text.x = element_text(size=32,colour="white"),
        axis.title.x = element_text(vjust=0.1,colour="white"),
        axis.text.y=element_text(angle=90, hjust=.5, size=32,colour="white"),
        axis.title.y=element_text(margin=margin(0,20,0,0),colour="white"),
        plot.background = element_rect(fill = "transparent", colour = NA),
        panel.grid.major.x = element_blank())  + 
  scale_y_continuous(limits = c(0, 1)) + 
  geom_hline(aes(yintercept=.5),size=2)# +
  #scale_y_continuous(expand = c(0, 0), limits = c(0,1.2))

t.test(WL2$EJ.Purple,mu=.5) # Ho: mu=0.5
t.test(WL2$Ask.Purple,mu=.5)
t.test(WL2$Word.Purple,mu=.5)
t.test(WL2$EJ.Orange,mu=.5) # Ho: mu=0.5
t.test(WL2$Ask.Orange,mu=.5)
t.test(WL2$Word.Orange,mu=.5)

#For future rmarkdown pdf use
# \begin{center}
#   \begin{tabular}{lccc}
#     \hline
#     Question & Proportion & t(`r EJ.ttest$parameter`) & 95\% CI\\
#     \hline
#     'Explicit judgment' & `r round(EJ.ttest$estimate,2)`(`r round(std.error(WL2$EJ.Match),2)`) & `r round(EJ.ttest$statistic,2)` & `r round(EJ.ttest$conf.int,2)` \\
#     Ask & `r round(Ask.ttest$estimate,2)`(`r round(std.error(WL2$Ask.Match),2)`) & `r round(Ask.ttest$statistic,2)` & `r round(Ask.ttest$conf.int,2)` \\
#     Endorse & `r round(Word.ttest$estimate,2)`(`r round(std.error(WL2$Word.Match),2)`) & `r round(Word.ttest$statistic,2)` & `r round(Word.ttest$conf.int,2)` \\
#   \end{tabular}
# \end{center}
```

```{r WL2_mind}
ggplot(data=WL2, aes(WL2$AgIndex)) + geom_histogram(breaks=seq(0, 3, by = .33))
ggplot(data=WL2, aes(WL2$ExpIndex)) + geom_histogram(breaks=seq(0, 3, by = .33))
ggplot(data=WL2, aes(WL2$MindIndex)) + geom_histogram(breaks=seq(0, 3, by = .33))
```

#Predicting Total Correct
```{r WL2_correlations}
#Agency

cor.test(WL2$Total,WL2$AgIndex)
AgencyTotal.Data = data.frame(Endorsement = WL2$Total, Agency = WL2$AgIndex)

ggplot(AgencyTotal.Data, aes(Agency,Endorsement)) + 
  geom_point(position = position_jitter(w = 0.05, h = 0.05), size=4, color=wes_palette(n=5, name=wesanderson)[1]) + 
  geom_smooth(method=lm, colour=wes_palette(n=5, name=wesanderson)[5], size=3) +
  scale_color_manual(values=wes_palette(n=1, name=wesanderson)) + 
  labs(y="Proportion of Correct Responses") + 
  theme(text = element_text(size=36,family="Corbel",colour="white"),
        axis.text.x = element_text(size=32,colour="white"),
        axis.title.x = element_text(vjust=0.1,colour="white"),
        axis.text.y=element_text(angle=90, hjust=.5, size=32,colour="white"),
        axis.title.y=element_text(margin=margin(0,20,0,0),colour="white"),
        plot.background = element_rect(fill = "transparent", colour = NA))

#Experience
cor.test(WL2$Total,WL2$ExpIndex)
ExpTotal.Data = data.frame(Endorsement = WL2$Total, Experience = WL2$ExpIndex)

ExpPlot = ggplot(ExpTotal.Data, aes(Experience,Endorsement))
ExpPlot +  geom_point(position = position_jitter(w = 0.2, h = 0.2)) + geom_smooth(method=lm)
```


```{r combined_mind_plot}

WL1.mind = WL1[c("AgIndex","ExpIndex","MindIndex","Subject")]
names(WL1.mind) = c("Agency","Experience","Mind","Participant")
WL1.mind = melt(WL1.mind,id='Participant')
names(WL1.mind) = c("Participant","Attributions of Mind","Responses")

WL2.mind = WL2[c("AgIndex","ExpIndex","MindIndex","Subject")]
names(WL2.mind) = c("Agency","Experience","Mind","Participant")
WL2.mind = melt(WL2.mind,id='Participant')
names(WL2.mind) = c("Participant","Attributions of Mind","Responses")

WL1.performance <- aggregate(WL1.mind$Responses,
    by = list("Attributions of Mind" = WL1.mind$`Attributions of Mind`),
    FUN = function(x) c(mean = mean(x,na.rm=T), sd = sd(x,na.rm=T), n = length(x)))

WL2.performance <- aggregate(WL2.mind$Responses,
    by = list("Attributions of Mind" = WL2.mind$`Attributions of Mind`),
    FUN = function(x) c(mean = mean(x,na.rm=T), sd = sd(x,na.rm=T), n = length(x)))

WL1.performance <- do.call(data.frame, WL1.performance)
WL1.performance$CI <- qt(0.975,df=WL1.performance$x.n-1)*WL1.performance$x.sd/sqrt(WL1.performance$x.n)
WL1.performance$type = "Robot"

WL2.performance <- do.call(data.frame, WL2.performance)
WL2.performance$CI <- qt(0.975,df=WL2.performance$x.n-1)*WL2.performance$x.sd/sqrt(WL2.performance$x.n)
WL2.performance$type = "Machine"

WL1.performance = WL1.performance[c("Attributions.of.Mind","x.mean","CI","type")]
names(WL1.performance) = c("Attributions of Mind","Responses","CI","Agent")

WL2.performance = WL2.performance[c("Attributions.of.Mind","x.mean","CI","type")]
names(WL2.performance) = c("Attributions of Mind","Responses","CI","Agent")

performance = rbind(WL1.performance,WL2.performance)

ggplot(data = performance, aes(x = `Attributions of Mind`, y = `Responses`, fill = `Agent`)) + 
  geom_bar(width = .6, position=position_dodge(), stat="identity") + 
  geom_errorbar(aes(ymin=performance$Responses-performance$CI, ymax=performance$Responses+performance$CI),
                width=.1,
                size = 1.2, # Width of the error bars
                position=position_dodge(.6)) + 
  labs(y="Responses") +
  theme(text = element_text(size=16,family="Corbel"),
        #axis.text.x = element_text(size=18),
        axis.title.x = element_text(vjust=0.1,size=20),
        axis.text.y=element_text(angle=90, hjust=.5, size=16),
        axis.title.y=element_text(margin=margin(0,20,0,0),size=20))

t.test(WL1.mind$Responses[WL1.mind$`Attributions of Mind`=="Agency"],WL2.mind$Responses[WL2.mind$`Attributions of Mind`=="Agency"],paired=FALSE)

t.test(WL1.mind$Responses[WL1.mind$`Attributions of Mind`=="Experience"],WL2.mind$Responses[WL2.mind$`Attributions of Mind`=="Experience"],paired=FALSE)

t.test(WL1.mind$Responses[WL1.mind$`Attributions of Mind`=="Mind"],WL2.mind$Responses[WL2.mind$`Attributions of Mind`=="Mind"],paired=FALSE)
```

```{r}
postscript("/tmp/test.eps", fonts=c("serif"))
wes_palette(name=wesanderson,n=5)
```

