---
title: "Word Learning"
author: "Kimberly A. Brink"
date: '`r format(Sys.Date(),"%B %d, %Y")`'
output: html_document
---

"Word Learning" is a study that assesses whether children will selectively trust a robot that provides accurate information compared to a robot that provides inaccurate information. Children watch two robots name a series of familiar objects, where one robot always names the object correctly and the other robot always incorrectly names the robot. The two robots are distingushed by their colors. 

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.path='Figures/', dev=c('png','postscript'), fig.width = 8, fig.height = 8, echo=FALSE, warning=FALSE, message=FALSE)
```

```{r standard_error}
std.error <- function(x) sd(x,na.rm=TRUE)/sqrt(length(x))
```

```{r libraries}
library(lubridate)
library(pander)
library(MASS)
library(QuantPsyc)
library(ggplot2)
library(reshape2)
options("scipen"=100, "digits"= 4)
```

```{r settings}
color = rgb(249/255,175/255,61/255)
```

```{r import}
#Import results from qualtrics using the qualtrics API (username, token, and surveyID removed)
#https://api.qualtrics.com/

 version = '2.5' #qualtrics version
 request = 'getLegacyResponseData' #Returns all of the response data for a survey in the original (legacy) data format.
 username = '' #hidden
 token = '' #hidden
 format = 'CSV' #comma-separated value format
 surveyID = '' #hidden
 exportTags = '1' #f 1 (true) the export tags will be used rather than the V labels. The default is 0.
 labels = '1' #If 1 (true) the label for choices and answers will be used and not the id. The default is 0.
 UnansweredRecode = '-99' #missing value coding
 
 #function that imports all responses from the qualtrics website and saves it to a data frame
 getSurveyResults <- function (version, request, username, token, format, surveyid,exportTags,labels)
 {
     url = paste("https://umich.qualtrics.com//WRAPI/ControlPanel/api.php?API_SELECT=ControlPanel", 
                 '&Version=', version,
                 '&Request=', request,
                 '&User=', username,
                 '&Token=', token,
                 '&Format=', format,
                 "&SurveyID=", surveyid,
                 "&ExportTags=", exportTags,
                 "&Labels=", labels,
                 "&UnansweredRecode=-99",sep='')
 
     t = read.csv(url)
     for (i in 1:10){ names(t)[i] <- as.character(t[1,i]) }
     t<-t[-1,]
 }
 
#save messy data to qualtrics.WL data frame
qualtrics.WL <- getSurveyResults(version, request, username, token, format, surveyID, exportTags, labels)
```

```{r formatting}
#Clean the data set

#Subset the data set by condition (i.e., by the order in which the robots are presented and by which robot is accurate)
WL.A <- subset(qualtrics.WL, Condition==1 & AccurateRobot=='Purple')
WL.B <- subset(qualtrics.WL, Condition==2 & AccurateRobot=='Purple')
WL.C <- subset(qualtrics.WL, Condition==1 & AccurateRobot=='Orange')
WL.D <- subset(qualtrics.WL, Condition==2 & AccurateRobot=='Orange')

#Each condition of the survey has different question names for the same questions. 
#Remove all unused variable names from each condition

WL.A <- WL.A[, c("ResponseID","StartDate","Finished","Condition","AccurateRobot","Subject","Sex","DOB","DOT","Fam1","Fam1_TEXT","Fam2","Fam2_TEXT","Fam3","Fam3_TEXT","Fam4","Fam4_TEXT","EJ1","Ask1A","Ask1A_TEXT","Ask1B","Ask1C","Ask2A","Ask2A_TEXT","Ask2B","Ask2C","Ask3A","Ask3A_TEXT","Ask3B","Ask3C","Ask4A","Ask4A_TEXT","Ask4B","Ask4C","EJ2","WHYCHOOSE","WHY","CANDY","CHOOSE","THINK","MORAL","PAIN","FEELINGS","SCARED","HUNGRY","P.SEX","O.SEX","OLDER","Audio_file","Comments")] 

WL.B <- WL.B[, c("ResponseID","StartDate","Finished","Condition","AccurateRobot","Subject","Sex","DOB","DOT","Fam1.2","Fam1_TEXT.2","Fam2.2","Fam2_TEXT.2","Fam3.2","Fam3_TEXT.2","Fam4.2","Fam4_TEXT.2","EJ1.2","Ask1A.1","Ask1A_TEXT.1","Ask1B.1","Ask1C.1","Ask2A.1","Ask2A_TEXT.1","Ask2B.1","Ask2C.1","Ask3A.1","Ask3A_TEXT.1","Ask3B.1","Ask3C.1","Ask4A.1","Ask4A_TEXT.1","Ask4B.1","Ask4C.1","EJ2.1","WHYCHOOSE","WHY","CANDY","CHOOSE","THINK","MORAL","PAIN","FEELINGS","SCARED","HUNGRY","P.SEX","O.SEX","OLDER","Audio_file","Comments")]

WL.C <- WL.C[, c("ResponseID","StartDate","Finished","Condition","AccurateRobot","Subject","Sex","DOB","DOT","Fam1.1","Fam1_TEXT.1","Fam2.1","Fam2_TEXT.1","Fam3.1","Fam3_TEXT.1","Fam4.1","Fam4_TEXT.1","EJ1.1","Ask1A","Ask1A_TEXT","Ask1B","Ask1C","Ask2A","Ask2A_TEXT","Ask2B","Ask2C","Ask3A","Ask3A_TEXT","Ask3B","Ask3C","Ask4A","Ask4A_TEXT","Ask4B","Ask4C","EJ2","WHYCHOOSE","WHY","CANDY","CHOOSE","THINK","MORAL","PAIN","FEELINGS","SCARED","HUNGRY","P.SEX","O.SEX","OLDER","Audio_file","Comments")] 

WL.D <- WL.D[, c("ResponseID","StartDate","Finished","Condition","AccurateRobot","Subject","Sex","DOB","DOT","Fam1.3","Fam1_TEXT.3","Fam2.3","Fam2_TEXT.3","Fam3.3","Fam3_TEXT.3","Fam4.3","Fam4_TEXT.3","EJ1.3","Ask1A.1","Ask1A_TEXT.1","Ask1B.1","Ask1C.1","Ask2A.1","Ask2A_TEXT.1","Ask2B.1","Ask2C.1","Ask3A.1","Ask3A_TEXT.1","Ask3B.1","Ask3C.1","Ask4A.1","Ask4A_TEXT.1","Ask4B.1","Ask4C.1","EJ2.1","WHYCHOOSE","WHY","CANDY","CHOOSE","THINK","MORAL","PAIN","FEELINGS","SCARED","HUNGRY","P.SEX","O.SEX","OLDER","Audio_file","Comments")]

#Rename all variables so that they have the same names across conditions
names(WL.A) <- c("ResponseID","StartDate","Finished","Condition","AccurateRobot","Subject","Sex","DOB","DOT","Fam1","Fam1_TEXT","Fam2","Fam2_TEXT","Fam3","Fam3_TEXT","Fam4","Fam4_TEXT","EJ1","Ask1A","Ask1A_TEXT","Ask1B","Ask1C","Ask2A","Ask2A_TEXT","Ask2B","Ask2C","Ask3A","Ask3A_TEXT","Ask3B","Ask3C","Ask4A","Ask4A_TEXT","Ask4B","Ask4C","EJ2","WHYCHOOSE","WHY","CANDY","CHOOSE","THINK","MORAL","PAIN","FEELINGS","SCARED","HUNGRY","P.SEX","O.SEX","OLDER","Audio_file","Comments")

names(WL.B) <- c("ResponseID","StartDate","Finished","Condition","AccurateRobot","Subject","Sex","DOB","DOT","Fam1","Fam1_TEXT","Fam2","Fam2_TEXT","Fam3","Fam3_TEXT","Fam4","Fam4_TEXT","EJ1","Ask1A","Ask1A_TEXT","Ask1B","Ask1C","Ask2A","Ask2A_TEXT","Ask2B","Ask2C","Ask3A","Ask3A_TEXT","Ask3B","Ask3C","Ask4A","Ask4A_TEXT","Ask4B","Ask4C","EJ2","WHYCHOOSE","WHY","CANDY","CHOOSE","THINK","MORAL","PAIN","FEELINGS","SCARED","HUNGRY","P.SEX","O.SEX","OLDER","Audio_file","Comments")

names(WL.C) <- c("ResponseID","StartDate","Finished","Condition","AccurateRobot","Subject","Sex","DOB","DOT","Fam1","Fam1_TEXT","Fam2","Fam2_TEXT","Fam3","Fam3_TEXT","Fam4","Fam4_TEXT","EJ1","Ask1A","Ask1A_TEXT","Ask1B","Ask1C","Ask2A","Ask2A_TEXT","Ask2B","Ask2C","Ask3A","Ask3A_TEXT","Ask3B","Ask3C","Ask4A","Ask4A_TEXT","Ask4B","Ask4C","EJ2","WHYCHOOSE","WHY","CANDY","CHOOSE","THINK","MORAL","PAIN","FEELINGS","SCARED","HUNGRY","P.SEX","O.SEX","OLDER","Audio_file","Comments")

names(WL.D) <- c("ResponseID","StartDate","Finished","Condition","AccurateRobot","Subject","Sex","DOB","DOT","Fam1","Fam1_TEXT","Fam2","Fam2_TEXT","Fam3","Fam3_TEXT","Fam4","Fam4_TEXT","EJ1","Ask1A","Ask1A_TEXT","Ask1B","Ask1C","Ask2A","Ask2A_TEXT","Ask2B","Ask2C","Ask3A","Ask3A_TEXT","Ask3B","Ask3C","Ask4A","Ask4A_TEXT","Ask4B","Ask4C","EJ2","WHYCHOOSE","WHY","CANDY","CHOOSE","THINK","MORAL","PAIN","FEELINGS","SCARED","HUNGRY","P.SEX","O.SEX","OLDER","Audio_file","Comments")

#Add a new variable to each data set which contains the condition name for each participant
WL.A$Order = "A"
WL.B$Order = "B"
WL.C$Order = "C"
WL.D$Order = "D"

#Combine all data into one dataset
WL <- rbind(WL.A,WL.B,WL.C,WL.D)
```

```{r preprocessing}
#Set all missing values to NA
WL[ WL == "" ] = NA
WL[ WL == -99 ] = NA


WL[WL$Subject == "010AnA",]$DOB = '06/13/2012' #error in experimenter data entry

#Convert categorical variables to factors
WL$AccurateRobot = factor(WL$AccurateRobot)
WL$EJ1 = factor(WL$EJ1)
WL$EJ2 = factor(WL$EJ2)

WL$Ask1B = factor(WL$Ask1B)
WL$Ask2B = factor(WL$Ask2B)
WL$Ask3B = factor(WL$Ask3B)
WL$Ask4B = factor(WL$Ask4B)

WL$Ask1C = factor(WL$Ask1C)
WL$Ask2C = factor(WL$Ask1C)
WL$Ask3C = factor(WL$Ask3C)
WL$Ask4C = factor(WL$Ask4C)
```

```{r variables}
#Convert date variables to a format that can be processed by R
WL$DOB = mdy(WL$DOB)
WL$DOT = mdy(WL$DOT)

#Calculate the age of each participant in months
WL$Age = year(as.period(interval(WL$DOB, WL$DOT)))*12 + month(as.period(interval(WL$DOB, WL$DOT))) + day(as.period(interval(WL$DOB, WL$DOT)))/30

WL$AgeYears = WL$Age/12

#Calculate whether children accurately answered all familiarization trials.
WL$Fam.Match = ifelse(WL$Fam1=="Brush",1,0) + ifelse(WL$Fam2=="Doll",1,0) + ifelse(WL$Fam3=="Ball",1,0) + ifelse(WL$Fam4=="Bear",1,0)

#Calculate the proportion of answers where children accurately determined which robot was bad at naming the familiar objects 
WL$EJ1.Match = ifelse(WL$EJ1!=WL$AccurateRobot,1,0)
WL$EJ2.Match = ifelse(WL$EJ2!=WL$AccurateRobot,1,0)
WL$EJ.Match = rowMeans(WL[c('EJ1.Match','EJ2.Match')],na.rm=T)
WL$EJ.Match[is.nan(WL$EJ.Match)]=NA

WL$EJ1.Purple = ifelse(WL$EJ1!="Purple",1,0)
WL$EJ2.Purple = ifelse(WL$EJ2!="Purple",1,0)
WL$EJ.Purple = rowMeans(WL[c('EJ1.Purple','EJ2.Purple')],na.rm=T)
WL$EJ.Purple[is.nan(WL$EJ.Purple)]=NA

WL$EJ1.Orange = ifelse(WL$EJ1!="Orange",1,0)
WL$EJ2.Orange = ifelse(WL$EJ2!="Orange",1,0)
WL$EJ.Orange = rowMeans(WL[c('EJ1.Orange','EJ2.Orange')],na.rm=T)
WL$EJ.Orange[is.nan(WL$EJ.Orange)]=NA

#Calculate the proportion of answers where children said they would ask the accurate robot for the name of the novel object
WL$Ask1B.Match = ifelse(WL$Ask1B==WL$AccurateRobot,1,0)
WL$Ask2B.Match = ifelse(WL$Ask2B==WL$AccurateRobot,1,0)
WL$Ask3B.Match = ifelse(WL$Ask3B==WL$AccurateRobot,1,0)
WL$Ask4B.Match = ifelse(WL$Ask4B==WL$AccurateRobot,1,0)
WL$Ask.Match = rowMeans(WL[c('Ask1B.Match','Ask2B.Match','Ask3B.Match','Ask4B.Match')],na.rm=T)
WL$Ask.Match[is.nan(WL$Ask.Match)]=NA

WL$Ask1B.Purple = ifelse(WL$Ask1B=='Purple',1,0)
WL$Ask2B.Purple = ifelse(WL$Ask2B=='Purple',1,0)
WL$Ask3B.Purple = ifelse(WL$Ask3B=='Purple',1,0)
WL$Ask4B.Purple = ifelse(WL$Ask4B=='Purple',1,0)
WL$Ask.Purple = rowMeans(WL[c('Ask1B.Purple','Ask2B.Purple','Ask3B.Purple','Ask4B.Purple')],na.rm=T)
WL$Ask.Purple[is.nan(WL$Ask.Purple)]=NA

WL$Ask1B.Orange = ifelse(WL$Ask1B=='Orange',1,0)
WL$Ask2B.Orange = ifelse(WL$Ask2B=='Orange',1,0)
WL$Ask3B.Orange = ifelse(WL$Ask3B=='Orange',1,0)
WL$Ask4B.Orange = ifelse(WL$Ask4B=='Orange',1,0)
WL$Ask.Orange = rowMeans(WL[c('Ask1B.Orange','Ask2B.Orange','Ask3B.Orange','Ask4B.Orange')],na.rm=T)
WL$Ask.Orange[is.nan(WL$Ask.Orange)]=NA

WL$Ask.bin = factor(ifelse(WL$Ask.Match <= mean(WL$Ask.Match,na.rm=T), 0, 1))

#Calculate the proportion of answers where children chose the same name that the accurate robot chose
WL$Ask1C.Match = ifelse(WL$Ask1C==WL$AccurateRobot,1,0)
WL$Ask2C.Match = ifelse(WL$Ask2C==WL$AccurateRobot,1,0)
WL$Ask3C.Match = ifelse(WL$Ask3C==WL$AccurateRobot,1,0)
WL$Ask4C.Match = ifelse(WL$Ask4C==WL$AccurateRobot,1,0)
WL$Word.Match = rowMeans(WL[c('Ask1C.Match','Ask2C.Match','Ask3C.Match','Ask4C.Match')],na.rm=T)
WL$Word.Match[is.nan(WL$Ask.Match)]=NA

WL$Ask1C.Purple = ifelse(WL$Ask1C=='Purple',1,0)
WL$Ask2C.Purple = ifelse(WL$Ask2C=='Purple',1,0)
WL$Ask3C.Purple = ifelse(WL$Ask3C=='Purple',1,0)
WL$Ask4C.Purple = ifelse(WL$Ask4C=='Purple',1,0)
WL$Word.Purple = rowMeans(WL[c('Ask1C.Purple','Ask2C.Purple','Ask3C.Purple','Ask4C.Purple')],na.rm=T)
WL$Word.Purple[is.nan(WL$Ask.Purple)]=NA

WL$Ask1C.Orange = ifelse(WL$Ask1C=='Orange',1,0)
WL$Ask2C.Orange = ifelse(WL$Ask2C=='Orange',1,0)
WL$Ask3C.Orange = ifelse(WL$Ask3C=='Orange',1,0)
WL$Ask4C.Orange = ifelse(WL$Ask4C=='Orange',1,0)
WL$Word.Orange = rowMeans(WL[c('Ask1C.Orange','Ask2C.Orange','Ask3C.Orange','Ask4C.Orange')],na.rm=T)
WL$Word.Orange[is.nan(WL$Ask.Orange)]=NA

WL$Word.bin = factor(ifelse(WL$Word.Match <= mean(WL$Word.Match,na.rm=T), 0, 1))

WL$Total = rowMeans(WL[c('EJ1.Match','EJ2.Match','Ask1B.Match','Ask2B.Match','Ask3B.Match','Ask4B.Match','Ask1C.Orange','Ask2C.Orange','Ask3C.Orange','Ask4C.Orange')],na.rm=T)

WL$Total.bin = factor(ifelse(WL$Total <= mean(WL$Total,na.rm=T), 0, 1))
```

There were `r sum(grepl("No Show",WL$Comments))+sum(grepl("No show",WL$Comments))` no shows.
There were `r sum(grepl("Cancelled",WL$Comments))+sum(grepl("cancelled",WL$Comments))+sum(grepl("Canceled",WL$Comments))+sum(grepl("canceled",WL$Comments))` cancelled appointments
There were `r sum(grepl("Fuss out",WL$Comments))+sum(grepl("fuss out",WL$Comments))` fuss outs.

```{r excluding}
WL = WL[!is.na(WL$Fam.Match),]
WL = WL[WL$Subject!="Test",]
WL = WL[WL$Subject!="Test2",]
```

 
##Demographics
There are `r dim(WL)[1]` participants.

The average age of the sample is `r round(mean(WL$Age), digits = 2)` months.

The median age of the sample is `r round(median(WL$Age), digits = 2)` months.

The minimum age of the sample is `r round(min(WL$Age), digits = 2)` months.

The maximum age of the sample is `r round(max(WL$Age), digits = 2)` months.

There are `r sum(WL$Sex == "Female")` females in the sample.

The first date of test was `r min(WL$DOT)`.

The most recent date of test was `r max(WL$DOT)`.


```{r descriptives}
#calculate summary statistics for age of sample
panderOptions("digits", 4)
pander(summary(WL$Age), caption = 'Age(months)')
hist(WL$Age,main='',xlab='Age(months)', col=color)

pander(summary(WL$AgeYears), caption = 'Age(years)')
hist(WL$AgeYears, main='',xlab='Age(years)', col=color)

#report how many participants completed each order of the survey
pander(table(WL$Order),caption = 'Distribution by Order of Presentation')
```

##Performance during accuracy trials 
```{r accuracy_trials}
#report summary statistics for performance during familiarization/accuracy trials
pander(summary(WL$Fam.Match))
hist(WL$Fam.Match,main='',xlab='Num correct', col=color)
pander(table(WL$Fam.Match),caption='Participant Count by Number of Trials Correct')
```

```{r familiarization_error}
#Remove all participants that failed to correctly answer all four familiarization trials
WL = WL[which(WL$Fam.Match==4),]

pander(table(WL$Order),caption = 'Distribution by Order of Presentation after removing for familiarization')
```

Now there are `r dim(WL)[1]` participants after removing for familiarization errors. 

```{r exploration}
t.test(WL$Total~WL$Sex) #no significant effect of age (this one's close)

pander(summary(aov(Total~Order, data=WL))) #no significant effect of order (thank god)
```

#Comparisons with chance for three test questions.
```{r performance}
#Report summary statistics for accuracy on judgment questions
pander(summary(WL$EJ.Match), caption='Proportion of Explicit Judgment Questions Correct')
hist(WL$EJ.Match,main='',xlab='Proportion of explicit judgment correct', col=color)

#Report summary statistics for accuracy on ask questions
pander(summary(WL$Ask.Match),caption='Proportion of Ask Questions correct')
hist(WL$Ask.Match,main='',xlab='Proportion of Ask Questions correct',col=color)

#Report summary statistics for accuracy on endorse questions
pander(summary(WL$Word.Match), caption = 'Proportion of Endorsement Questions correct')
hist(WL$Word.Match, main='',xlab='Proportion of Endorsement Questions correct',col=color)

pander(summary(WL$Total), caption = 'Performance across all questions')
hist(WL$Total, main='',xlab='Performance',col=color)

#Compare performance to chance guessing
EJ.ttest = t.test(WL$EJ.Match,mu=.5) # Ho: mu=0.5
Ask.ttest = t.test(WL$Ask.Match,mu=.5)
Word.ttest = t.test(WL$Word.Match,mu=.5)

chance.table = data.frame(Question = c('Explicit judgment','Ask','Endorse'), 
                          Proportion = c(
                            paste(round(EJ.ttest$estimate,2),
                                  '(',round(std.error(WL$EJ.Match),2),')',sep=''), 
                            paste(round(Ask.ttest$estimate,2),
                                  '(',round(std.error(WL$Ask.Match),2),')',sep=''),
                            paste(round(Word.ttest$estimate,2),
                                  '(',round(std.error(WL$Word.Match),2),')',sep='')), 
                          't(df)' = c(
                            paste(round(EJ.ttest$statistic,2),
                                  '(',round(EJ.ttest$parameter,2),')',sep=''), 
                            paste(round(Ask.ttest$statistic,2),
                                  '(',round(Ask.ttest$parameter,2),')',sep=''),
                            paste(round(Word.ttest$statistic,2),
                                  '(',round(Word.ttest$parameter,2),')',sep='')),
                          '95%CI' = c(paste(round(EJ.ttest$conf.int[1],2),
                                             round(EJ.ttest$conf.int[2],2),sep=","),
                                       paste(round(Ask.ttest$conf.int[1],2),
                                             round(Ask.ttest$conf.int[2],2),sep=","),
                                       paste(round(Word.ttest$conf.int[1],2),
                                             round(Word.ttest$conf.int[2],2),sep=","))
                          )

pander(chance.table,style = 'rmarkdown')

WL.perf = WL[c("EJ.Match","Ask.Match","Word.Match","Subject")]
names(WL.perf) = c("Explicit Judgment","Ask","Endorse","Participant")
perf = melt(WL.perf,id='Participant')
names(perf) = c("Participant","Question Type","Proportion")

performance <- aggregate(perf$Proportion,
    by = list("Question Type" = perf$`Question Type`),
    FUN = function(x) c(mean = mean(x,na.rm=T), sd = sd(x,na.rm=T), n = length(x)))

performance <- do.call(data.frame, performance)
performance$CI <- qt(0.975,df=performance$x.n-1)*performance$x.sd/sqrt(performance$x.n)

performance = performance[c("Question.Type","x.mean","CI")]
names(performance) = c("Question Type","Proportion","CI")

p = ggplot(data = performance, aes(x = `Question Type`, y = Proportion, fill = `Question Type`))
p = p + guides(fill=FALSE)
p = p + geom_bar(width = .65, position=position_dodge(), stat="identity")
p = p + geom_errorbar(aes(ymin=performance$Proportion-performance$CI, ymax=performance$Proportion+performance$CI),
                        width=.2,
                        size = 2, # Width of the error bars
                        position=position_dodge(.65))
p+geom_hline(aes(yintercept=.5))

t.test(WL$EJ.Purple,mu=.5) # Ho: mu=0.5
t.test(WL$Ask.Purple,mu=.5)
t.test(WL$Word.Purple,mu=.5)
t.test(WL$EJ.Orange,mu=.5) # Ho: mu=0.5
t.test(WL$Ask.Orange,mu=.5)
t.test(WL$Word.Orange,mu=.5)

#For future rmarkdown pdf use
# \begin{center}
#   \begin{tabular}{lccc}
#     \hline
#     Question & Proportion & t(`r EJ.ttest$parameter`) & 95\% CI\\
#     \hline
#     'Explicit judgment' & `r round(EJ.ttest$estimate,2)`(`r round(std.error(WL$EJ.Match),2)`) & `r round(EJ.ttest$statistic,2)` & `r round(EJ.ttest$conf.int,2)` \\
#     Ask & `r round(Ask.ttest$estimate,2)`(`r round(std.error(WL$Ask.Match),2)`) & `r round(Ask.ttest$statistic,2)` & `r round(Ask.ttest$conf.int,2)` \\
#     Endorse & `r round(Word.ttest$estimate,2)`(`r round(std.error(WL$Word.Match),2)`) & `r round(Word.ttest$statistic,2)` & `r round(Word.ttest$conf.int,2)` \\
#   \end{tabular}
# \end{center}
```


```{r predictors}
#Recode perceptions of agency and experience questions
WL$THINK.score = ifelse(WL$THINK=="No",0,ifelse(WL$THINK=="A little bit",1,ifelse(WL$THINK=="A medium amount",2,ifelse(WL$THINK=="A lot",3,NA))))
WL$MORAL.score = ifelse(WL$MORAL=="No",0,ifelse(WL$MORAL=="A little bit",1,ifelse(WL$MORAL=="A medium amount",2,ifelse(WL$MORAL=="A lot",3,NA))))
WL$CHOOSE.score = ifelse(WL$CHOOSE=="No",0,ifelse(WL$CHOOSE=="A few things",1,ifelse(WL$CHOOSE=="A medium amount of things",2,ifelse(WL$CHOOSE=="A lot of things",3,NA))))
WL$PAIN.score = ifelse(WL$PAIN=="No",0,ifelse(WL$PAIN=="A little bit",1,ifelse(WL$PAIN=="A medium amount",2,ifelse(WL$PAIN=="A lot",3,NA))))
WL$SCARED.score = ifelse(WL$SCARED=="No",0,ifelse(WL$SCARED=="A little bit",1,ifelse(WL$SCARED=="A medium amount",2,ifelse(WL$SCARED=="A lot",3,NA))))
WL$HUNGRY.score = ifelse(WL$HUNGRY=="No",0,ifelse(WL$HUNGRY=="A little bit",1,ifelse(WL$HUNGRY=="A medium amount",2,ifelse(WL$HUNGRY=="A lot",3,NA))))

#Calculate aggregates of children's perceptions of the robots' agency and experience
WL$AgIndex = (WL$THINK.score + WL$MORAL.score + WL$CHOOSE.score)/3
WL$ExpIndex = (WL$PAIN.score + WL$SCARED.score + WL$HUNGRY.score)/3
WL$MindIndex = (WL$PAIN.score + WL$SCARED.score + WL$HUNGRY.score+WL$THINK.score + WL$MORAL.score + WL$CHOOSE.score)/6
WL$AgIndex.cent = scale(WL$AgIndex,center=T,scale=T)
WL$ExpIndex.cent = scale(WL$ExpIndex,center=T,scale=T)
WL$Age.cent = scale(WL$Age,center=T,scale=T)
WL$MindIndex.cent = scale(WL$MindIndex,center=T,scale=T)
```

```{r correlations_IV}
#Calculate correlations between aggregates and test questions

#Agency and experience
cor.test(WL$AgIndex,WL$ExpIndex)
ggplot(WL, aes(AgIndex,ExpIndex)) + geom_point(position = position_jitter(w = 0.2, h = 0.2)) + geom_smooth(method=lm)

#Age and experience
cor.test(WL$Age,WL$ExpIndex)
ggplot(WL, aes(Age,ExpIndex)) + geom_point(position = position_jitter(w = 0.2, h = 0.2)) + geom_smooth(method=lm)

#Ask and experience
cor.test(WL$Ask.Match,WL$ExpIndex)
ggplot(WL, aes(ExpIndex,Ask.Match)) + geom_point(position = position_jitter(w = 0.2, h = 0.2)) + geom_smooth(method=lm)

#Word and experience
cor.test(WL$Word.Match,WL$ExpIndex)
ggplot(WL, aes(ExpIndex,Ask.Match)) + geom_point(position = position_jitter(w = 0.2, h = 0.2)) + geom_smooth(method=lm)

#Age and agency
cor.test(WL$Age,WL$AgIndex)
ggplot(WL, aes(Age,AgIndex)) + geom_point(position = position_jitter(w = 0.2, h = 0.2)) + geom_smooth(method=lm)

#Ask and agency
cor.test(WL$Ask.Match,WL$AgIndex)
ggplot(WL, aes(AgIndex,Ask.Match)) + geom_point(position = position_jitter(w = 0.2, h = 0.2)) + geom_smooth(method=lm)

#Word and agency
cor.test(WL$Word.Match,WL$AgIndex)
ggplot(WL, aes(AgIndex,Word.Match)) + geom_point(position = position_jitter(w = 0.2, h = 0.2)) + geom_smooth(method=lm)
```

#Predicting Total Endorsement
```{r correlations}
#Agency
cor.test(WL$Total,WL$AgIndex)
AgencyTotal.Data = data.frame(Endorsement = WL$Total, Agency = WL$AgIndex)

AgencyPlot = ggplot(AgencyTotal.Data, aes(Agency,Endorsement))
AgencyPlot +  geom_point(position = position_jitter(w = 0.2, h = 0.2)) + geom_smooth(method=lm)

#Experience
cor.test(WL$Total,WL$ExpIndex)
ExpTotal.Data = data.frame(Endorsement = WL$Total, Experience = WL$ExpIndex)

ExpPlot = ggplot(ExpTotal.Data, aes(Experience,Endorsement))
ExpPlot +  geom_point(position = position_jitter(w = 0.2, h = 0.2)) + geom_smooth(method=lm)
```

##Regression Analyses
```{r regressions}
#assess which predictors predict responses to test questions
#summary(glm(Ask.Match~ExpIndex.cent+AgIndex.cent,data=WL))
#summary(glm(Word.Match~ExpIndex.cent*AgIndex.cent,data=WL))
summary(glm(Total~ExpIndex.cent+AgIndex.cent,data=WL))
lm.beta(glm(Total~ExpIndex.cent+AgIndex.cent,data=WL))

summary(glm(Total~ExpIndex.cent+AgIndex.cent+Age.cent,data=WL))

summary(glm(Total~ExpIndex.cent+AgIndex.cent+Age.cent+Sex,data=WL))

summary(glm(Total~AgIndex.cent+Age.cent,data=WL))

#plot(WL$Total~WL$AgIndex.cent,col=color,xlab='Agency',ylab='Performance',main="",lwd=4)
#abline(lm(Total~AgIndex.cent+Age.cent+Sex,data=WL),col=color,lwd=4)

summary(glm(Total.bin~ExpIndex.cent+AgIndex.cent+Age.cent+Sex,data=WL,family="binomial"))

```

```{r regression_mind}

#assess which predictors predict responses to test questions

summary(glm(Total~MindIndex.cent,data=WL))

summary(glm(Total~MindIndex.cent+Age.cent,data=WL))

summary(glm(Total~MindIndex.cent+Age.cent+Sex,data=WL))
summary(glm(Total~MindIndex.cent+Sex,data=WL))
```

```{r LDA_askbin, include=FALSE}
WL.red = WL[which(!is.na(WL$AgIndex.cent)&!is.na(WL$ExpIndex.cent)&!is.na(WL$Ask.bin)),]
set.seed(1)
train = sample(dim(WL.red)[1],dim(WL.red)[1]*.6)
sample.train <- WL.red[train,] 
sample.test <-WL.red[-train,] 

lda.fit.Ask = lda(Ask.bin~AgIndex.cent+Age.cent,data=sample.train)
lda.pred=predict(lda.fit.Ask,newdata=sample.test)
lda.class=lda.pred$class
mean(lda.class!=sample.test$Ask.bin)
```

```{r LDA_wordbin, include=FALSE}
WL.red = WL[which(!is.na(WL$AgIndex.cent)&!is.na(WL$ExpIndex.cent)&!is.na(WL$Word.bin)),]
set.seed(2000)
train = sample(dim(WL.red)[1],dim(WL.red)[1]*.6)
sample.train.Word <- WL.red[train,] 
sample.test.Word <-WL.red[-train,] 

lda.fit.Word = lda(Word.bin~Age+AgIndex,data=sample.train.Word)
lda.pred=predict(lda.fit.Word,newdata=sample.test.Word)
lda.class=lda.pred$class
#mean(lda.class!=sample.test.Word$Word.bin) #error rate

plot(lda.fit.Word,dimen=2)

#With age and agency index as predictors, the error rate for predicting whether the child was better or worse at matching the word of the accurate robot is `r round(mean(lda.class!=sample.test.Word$Word.bin),2)`.
```

```{r classification_plots, include=FALSE}
plot(WL$Age,jitter(WL$AgIndex),col=(ifelse(WL$Word.bin==1,'red','blue')), main = "Binary Word Match")
```

```{r MacKinnon_mediation}
#MacKinnon et al., 2007

#Estimate Equations 2 (Y = i + c'X + bM + e) and 3 (M = i + aX + e), i = intercept, e = error, M = mediator, X = predictor, y = criterion. Compute product of a & b.

#Equation 2
eq2 = lm(Total~Age.cent+AgIndex.cent,
         data=WL)
pander(summary(eq2))
pander(summary(eq2), caption='Is the slope of Agency significantly different from zero?')
b = eq2$coefficients[["AgIndex.cent"]]
var.b = (summary(eq2)$coef[,'Std. Error'][['AgIndex.cent']])^2
n.b = length(resid(eq2))

#Equation 3
eq3 = lm(AgIndex.cent~Age.cent,
         data=WL)
pander(summary(eq3), caption='Is the slope of Age significantly different from zero?')
a = eq3$coefficients[["Age.cent"]]
var.a = (summary(eq3)$coef[,'Std. Error'][['Age.cent']])^2
n.a = length(resid(eq3))

#To test for significance, the product is then divided by the standard error of the product and the ratio is compared to a standard normal distribution.

#variance of the roduct of two independent random variables (Goodman, 1960)
var.ab = a^2*(var.b/n.b) + b^2*(var.a/n.a) - ((var.a/n.a)*(var.b/n.b)) 

#The standard error of an estimate may also be defined as the square root of the estimated error 
se.ab = sqrt(abs(var.ab))

sig = (a*b)/se.ab
abs(sig)>1.96

#The rationale behind this method is that mediation depends on the extent to which the program changes the mediator, a, and the extent to which the mediator affects the outcome variable, b.
```

The product of the coefficients ab = `r round(a*b,4)`, t = `r round(sig,2)` (MacKinnon, Fairchild, & Fritz, 2007)

